{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9egJDg54BFAn",
        "outputId": "597ef72f-d83c-4841-dc94-38cde1251d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.237-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.237-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.237 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dilTdO4KA4xc",
        "outputId": "0fb8f1e5-9caa-40fc-8eb1-df3cc94d3fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import datetime\n",
        "import sys\n",
        "from filelock import FileLock\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import yaml\n",
        "import torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c83VM3l7A4xd"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 01. 디렉토리 및 유틸 함수 설정<br>\n",
        "════════════════════════════════════════"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0naGF9TaCaEe",
        "outputId": "39143e02-e475-46b0-f084-af1e7f823cd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEH1ukuCA4xe",
        "outputId": "99573443-55da-4ea0-f999-b3ee443dc8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "설정된 BASE_DIR: /content/drive/MyDrive/oraldrug/4.drug_Augmentation\n"
          ]
        }
      ],
      "source": [
        "VER = \"2025.12.12.001.bestOne\"\n",
        "#BASE_DIR = \"/content/drive/MyDrive/codeit/data\"\n",
        "#BASE_DIR = r\"D:\\01.project\\EntryPrj\\data\"\n",
        "BASE_DIR = '/content/drive/MyDrive/oraldrug/4.drug_Augmentation'\n",
        "\n",
        "print(\"설정된 BASE_DIR:\", BASE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qg_UYFPlA4xf"
      },
      "outputs": [],
      "source": [
        "LOG_FILE = os.path.join(BASE_DIR, \"operation.log\")\n",
        "SUBMISSTION_DIR = f\"{BASE_DIR}/submission\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nMtPLOpA4xf"
      },
      "source": [
        "데이터 디렉토리 설정 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBpuTUAHA4xf",
        "outputId": "cd6f5a0e-92e8-4d1d-8fb0-f31ae01733a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\E'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\E'\n",
            "/tmp/ipython-input-1860246394.py:6: SyntaxWarning: invalid escape sequence '\\E'\n",
            "  data_dir: 데이터 루트 디렉토리 (예: D:\\01.project\\EntryPrj\\data\\oraldrug\\4.drug_Augmentation)\n"
          ]
        }
      ],
      "source": [
        "def GetConfig(data_dir):\n",
        "    \"\"\"\n",
        "    데이터 디렉토리로부터 필요한 경로들을 생성\n",
        "\n",
        "    Args:\n",
        "        data_dir: 데이터 루트 디렉토리 (예: D:\\01.project\\EntryPrj\\data\\oraldrug\\4.drug_Augmentation)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (image_dir, annotation_dir, yaml_file, yaml_label_dir, test_img_dir)\n",
        "    \"\"\"\n",
        "    image_dir = os.path.join(data_dir, \"train_images\")\n",
        "    annotation_dir = os.path.join(data_dir, \"train_annotations\")\n",
        "    yaml_file = os.path.join(data_dir, \"yolo_yaml.yaml\")\n",
        "    yaml_label_dir = os.path.join(data_dir, \"yolo_labels\")\n",
        "    # test_img_dir는 oraldrug 디렉토리 밑에 위치 (data_dir의 부모 디렉토리)\n",
        "    parent_dir = os.path.dirname(data_dir)  # oraldrug 디렉토리\n",
        "    test_img_dir = os.path.join(parent_dir, \"test_images\")\n",
        "    return image_dir, annotation_dir, yaml_file, yaml_label_dir, test_img_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCNZEW_dA4xf"
      },
      "source": [
        "공통 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2eY9H7UBA4xf"
      },
      "outputs": [],
      "source": [
        "MODEL_FILES = os.path.join(BASE_DIR, \"modelfiles\")\n",
        "RESULT_CSV = f\"{BASE_DIR}/entryprj.csv\"\n",
        "DEVICE_TYPE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7vlI7kYA4xg"
      },
      "source": [
        " 구분선 출력 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rEQr5xgeA4xg"
      },
      "outputs": [],
      "source": [
        "def Lines(text=\"\", count=100):\n",
        "    print(\"═\" * count)\n",
        "    if text != \"\":\n",
        "        print(f\"{text}\")\n",
        "        print(\"═\" * count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C305XqsKA4xg"
      },
      "source": [
        " 현재 시간 문자열 반환 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_9L8NgxAA4xg"
      },
      "outputs": [],
      "source": [
        "def now_str():\n",
        "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS2U9teQA4xg"
      },
      "source": [
        " 디렉토리 생성 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "imCxyUZaA4xg"
      },
      "outputs": [],
      "source": [
        "def makedirs(d):\n",
        "    os.makedirs(d, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlbGDb7bA4xh"
      },
      "source": [
        " 운영 로그 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "59gUwmJbA4xh"
      },
      "outputs": [],
      "source": [
        "def OpLog(log, bLines=True):\n",
        "    if bLines:\n",
        "        Lines(f\"[{now_str()}] {log}\")\n",
        "    try:\n",
        "        caller_name = sys._getframe(1).f_code.co_name\n",
        "    except Exception:\n",
        "        caller_name = \"UnknownFunction\"\n",
        "    log_filename = LOG_FILE\n",
        "    log_lock_filename = log_filename + \".lock\"\n",
        "    log_content = f\"[{now_str()}] {caller_name}: {log}\\n\"\n",
        "    try:\n",
        "        lock = FileLock(log_lock_filename, timeout=10)\n",
        "        with lock:\n",
        "            with open(log_filename, \"a\", encoding=\"utf-8\") as f:\n",
        "                f.write(log_content)\n",
        "    except Exception as e:\n",
        "        print(f\"Log write error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwhczpweA4xh",
        "outputId": "3ebfa756-6d7b-4948-f50b-8ad2bee05238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-15 00:22:41] Start program.2025.12.12.001.bestOne\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        }
      ],
      "source": [
        "OpLog(f\"Start program.{VER}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6MG-V7nA4xh"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 02. 클래스 수 계산 및 클래스 매핑 생성<br>\n",
        "════════════════════════════════════════<br>\n",
        "train_annotations에서 JSON 파일을 읽어서 category_id로 클래스 수 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BQJNKmMmA4xh"
      },
      "outputs": [],
      "source": [
        "def count_classes(annotations_dir):\n",
        "    \"\"\"\n",
        "    모든 서브 디렉토리에서 JSON을 읽어서 category_id를 classes로 카운트\n",
        "    os.walk()를 사용하여 모든 하위 디렉토리를 재귀적으로 검사\n",
        "    Returns:\n",
        "        int: 고유 category_id 개수\n",
        "    \"\"\"\n",
        "    unique_category_ids = set()\n",
        "\n",
        "    # os.walk()로 모든 하위 디렉토리 재귀적으로 탐색\n",
        "    for root, dirs, files in os.walk(annotations_dir):\n",
        "        for json_file in files:\n",
        "            if json_file.endswith(\".json\"):\n",
        "                json_path = os.path.join(root, json_file)\n",
        "                try:\n",
        "                    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        data = json.load(f)\n",
        "                    # category_id 추출\n",
        "                    if \"annotations\" in data and len(data[\"annotations\"]) > 0:\n",
        "                        for ann in data[\"annotations\"]:\n",
        "                            category_id = ann.get(\"category_id\")\n",
        "                            if category_id is not None:\n",
        "                                # category_id를 int로 변환\n",
        "                                try:\n",
        "                                    category_id = int(category_id)\n",
        "                                    unique_category_ids.add(category_id)\n",
        "                                except (ValueError, TypeError):\n",
        "                                    continue\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "    return len(unique_category_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3HPQE1GUA4xh"
      },
      "outputs": [],
      "source": [
        "def get_class_mapping(annotations_dir):\n",
        "    \"\"\"\n",
        "    annotation 디렉토리에서 JSON을 읽어 category_id 기반으로 클래스 매핑 정보를 반환\n",
        "    os.walk()를 사용하여 모든 하위 디렉토리를 재귀적으로 검사\n",
        "    Args:\n",
        "        annotations_dir: annotation 디렉토리 경로\n",
        "    Returns:\n",
        "        tuple: (class_dirs, class_to_idx, idx_to_class, unique_classes)\n",
        "            - class_dirs: [(category_id, [json_paths]), ...] 리스트\n",
        "            - class_to_idx: {category_id: index} 딕셔너리 (category_id를 그대로 사용)\n",
        "            - idx_to_class: {index: category_id} 딕셔너리\n",
        "            - unique_classes: 정렬된 고유 category_id 리스트\n",
        "    \"\"\"\n",
        "    class_info = {}  # {category_id: [json_path1, json_path2, ...]}\n",
        "    class_dirs = []\n",
        "\n",
        "    # os.walk()로 모든 하위 디렉토리 재귀적으로 탐색\n",
        "    json_count = 0\n",
        "    for root, dirs, files in os.walk(annotations_dir):\n",
        "        for json_file in files:\n",
        "            if json_file.endswith(\".json\"):\n",
        "                json_path = os.path.join(root, json_file)\n",
        "                json_count += 1\n",
        "                try:\n",
        "                    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        data = json.load(f)\n",
        "                    if \"annotations\" in data and len(data[\"annotations\"]) > 0:\n",
        "                        for ann in data[\"annotations\"]:\n",
        "                            category_id = ann.get(\"category_id\")\n",
        "                            if category_id is not None:\n",
        "                                # category_id를 int로 변환 (문자열인 경우 대비)\n",
        "                                try:\n",
        "                                    category_id = int(category_id)\n",
        "                                except (ValueError, TypeError):\n",
        "                                    continue\n",
        "\n",
        "                                # 동일 category_id가 여러 JSON 파일에 있을 수 있으므로 모두 저장\n",
        "                                if category_id not in class_info:\n",
        "                                    class_info[category_id] = []\n",
        "                                if json_path not in class_info[category_id]:\n",
        "                                    class_info[category_id].append(json_path)\n",
        "                                break  # 한 JSON에서 category_id 하나만 찾으면 됨\n",
        "                except Exception as e:\n",
        "                    OpLog(f\"Error reading {json_path}: {e}\", bLines=False)\n",
        "                    continue\n",
        "    OpLog(f\"get_class_mapping: 총 {json_count}개 JSON 파일 스캔, {len(class_info)}개 클래스 발견\", bLines=False)\n",
        "\n",
        "    # class_dirs 생성 (category_id, JSON 파일 목록)\n",
        "    for category_id, json_paths in class_info.items():\n",
        "        class_dirs.append((category_id, json_paths))\n",
        "\n",
        "    # 클래스 정렬 및 인덱스 매핑 (0-based index로 변환)\n",
        "    unique_classes = sorted(class_info.keys())\n",
        "    # category_id를 0부터 시작하는 인덱스로 매핑\n",
        "    class_to_idx = {category_id: idx for idx, category_id in enumerate(unique_classes)}\n",
        "    idx_to_class = {idx: category_id for idx, category_id in enumerate(unique_classes)}\n",
        "    return class_dirs, class_to_idx, idx_to_class, unique_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HW3cI-WNA4xi"
      },
      "outputs": [],
      "source": [
        "def analyze_image_json_mapping(train_img_dir, annotation_dir, output_dir):\n",
        "    \"\"\"\n",
        "    이미지와 JSON 파일 간의 매핑 관계를 분석하여 CSV 파일로 저장\n",
        "\n",
        "    Args:\n",
        "        train_img_dir: 학습 이미지 디렉토리\n",
        "        annotation_dir: 어노테이션 디렉토리\n",
        "        output_dir: CSV 파일 저장 디렉토리\n",
        "    생성 파일:\n",
        "        - img_to_json.csv: 이미지 -> JSON 매핑 (이미지명, JSON경로)\n",
        "        - json_to_img.csv: JSON -> 이미지 매핑 (JSON경로, 이미지명)\n",
        "    \"\"\"\n",
        "    OpLog(\"이미지-JSON 매핑 분석 시작\", bLines=True)\n",
        "\n",
        "    img_to_json_file = os.path.join(output_dir, \"img_to_json.csv\")\n",
        "    json_to_img_file = os.path.join(output_dir, \"json_to_img.csv\")\n",
        "\n",
        "    # 1. train_img_dir 밑의 모든 이미지 파일 수집\n",
        "    image_files = {}  # {filename: full_path}\n",
        "    if os.path.exists(train_img_dir):\n",
        "        for img_file in os.listdir(train_img_dir):\n",
        "            if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
        "                image_files[img_file] = os.path.join(train_img_dir, img_file)\n",
        "    OpLog(f\"이미지 파일 수: {len(image_files)}\", bLines=False)\n",
        "\n",
        "    # 2. annotation_dir 밑의 모든 JSON 파일 수집\n",
        "    json_files = []  # [(json_path, images_in_json), ...]\n",
        "    if os.path.exists(annotation_dir):\n",
        "        for subdir in os.listdir(annotation_dir):\n",
        "            subdir_path = os.path.join(annotation_dir, subdir)\n",
        "            if os.path.isdir(subdir_path):\n",
        "                for class_dir in os.listdir(subdir_path):\n",
        "                    class_dir_path = os.path.join(subdir_path, class_dir)\n",
        "                    if os.path.isdir(class_dir_path):\n",
        "                        for json_file in os.listdir(class_dir_path):\n",
        "                            if json_file.endswith(\".json\"):\n",
        "                                json_path = os.path.join(class_dir_path, json_file)\n",
        "                                # JSON 파일에서 이미지 정보 추출\n",
        "                                try:\n",
        "                                    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                                        data = json.load(f)\n",
        "                                    images_in_json = []\n",
        "                                    if \"images\" in data:\n",
        "                                        for img_info in data[\"images\"]:\n",
        "                                            img_filename = img_info.get(\"file_name\", \"\")\n",
        "                                            if img_filename:\n",
        "                                                images_in_json.append(img_filename)\n",
        "                                    json_files.append((json_path, images_in_json))\n",
        "                                except Exception as e:\n",
        "                                    OpLog(\n",
        "                                        f\"JSON 파일 읽기 오류 {json_path}: {e}\",\n",
        "                                        bLines=False,\n",
        "                                    )\n",
        "    OpLog(f\"JSON 파일 수: {len(json_files)}\", bLines=False)\n",
        "\n",
        "    # 3. IMG_TO_JSON 매핑 생성\n",
        "    img_to_json_mapping = []  # [(img_name, json_path), ...]\n",
        "    for img_name in sorted(image_files.keys()):\n",
        "        found_jsons = []\n",
        "\n",
        "        # 이 이미지를 포함하는 JSON 파일 찾기\n",
        "        for json_path, images_in_json in json_files:\n",
        "            if img_name in images_in_json:\n",
        "                found_jsons.append(json_path)\n",
        "        if found_jsons:\n",
        "            for json_path in found_jsons:\n",
        "                img_to_json_mapping.append((img_name, json_path))\n",
        "        else:\n",
        "            # JSON 파일이 없는 이미지\n",
        "            img_to_json_mapping.append((img_name, \"NONE\"))\n",
        "\n",
        "    # 4. JSON_TO_IMG 매핑 생성\n",
        "    json_to_img_mapping = []  # [(json_path, img_name), ...]\n",
        "    for json_path, images_in_json in json_files:\n",
        "        if images_in_json:\n",
        "            for img_name in images_in_json:\n",
        "                # 실제 이미지 파일이 존재하는지 확인\n",
        "                if img_name in image_files:\n",
        "                    json_to_img_mapping.append((json_path, img_name))\n",
        "                else:\n",
        "                    json_to_img_mapping.append((json_path, \"NONE\"))\n",
        "        else:\n",
        "            # 이미지 정보가 없는 JSON\n",
        "            json_to_img_mapping.append((json_path, \"NONE\"))\n",
        "\n",
        "    # 5. IMG_TO_JSON CSV 파일 저장\n",
        "    makedirs(os.path.dirname(img_to_json_file))\n",
        "    with open(img_to_json_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Image,JSON\\n\")\n",
        "        for img_name, json_path in img_to_json_mapping:\n",
        "            f.write(f\"{img_name},{json_path}\\n\")\n",
        "    OpLog(\n",
        "        f\"IMG_TO_JSON 저장 완료: {img_to_json_file} ({len(img_to_json_mapping)}개 매핑)\",\n",
        "        bLines=False,\n",
        "    )\n",
        "\n",
        "    # 6. JSON_TO_IMG CSV 파일 저장\n",
        "    with open(json_to_img_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"JSON,Image\\n\")\n",
        "        for json_path, img_name in json_to_img_mapping:\n",
        "            f.write(f\"{json_path},{img_name}\\n\")\n",
        "    OpLog(\n",
        "        f\"JSON_TO_IMG 저장 완룜: {json_to_img_file} ({len(json_to_img_mapping)}개 매핑)\",\n",
        "        bLines=False,\n",
        "    )\n",
        "\n",
        "    # 7. 통계 정보 출력\n",
        "    img_without_json = sum(\n",
        "        1 for _, json_path in img_to_json_mapping if json_path == \"NONE\"\n",
        "    )\n",
        "    json_without_img = sum(\n",
        "        1 for _, img_name in json_to_img_mapping if img_name == \"NONE\"\n",
        "    )\n",
        "    OpLog(f\"매핑 분석 완료:\", bLines=True)\n",
        "    OpLog(f\"  - 전체 이미지: {len(image_files)}개\", bLines=False)\n",
        "    OpLog(f\"  - 전체 JSON: {len(json_files)}개\", bLines=False)\n",
        "    OpLog(f\"  - JSON 없는 이미지: {img_without_json}개\", bLines=False)\n",
        "    OpLog(f\"  - 이미지 없는 JSON: {json_without_img}개\", bLines=False)\n",
        "    return img_to_json_mapping, json_to_img_mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll06uCQ5A4xi"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 03. 데이터셋 및 데이터 증강 함수 정의<br>\n",
        "════════════════════════════════════════<br>\n",
        "다양한 데이터 증강(transform) 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dE_ciBzOA4xi"
      },
      "outputs": [],
      "source": [
        "def GetTransform(transform_type=\"default\"):\n",
        "    if transform_type == \"default\":\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "    if transform_type == \"A\":\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ColorJitter(\n",
        "                    brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1\n",
        "                ),\n",
        "                transforms.RandomRotation(degrees=15),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "    elif transform_type == \"B\":\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.RandomAffine(\n",
        "                    degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)\n",
        "                ),\n",
        "                transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJHr1xfcA4xi"
      },
      "source": [
        "커스텀 데이터셋 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RcsuES-AA4xi"
      },
      "outputs": [],
      "source": [
        "class PillDataset(Dataset):\n",
        "    def __init__(self, annotations_dir, img_dir, transform=None, is_test=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            annotations_dir: train_annotations 경로 (is_test=True일 경우 무시됨)\n",
        "            img_dir: train_images 또는 test_images 경로\n",
        "            transform: 이미지 변환 함수\n",
        "            is_test: 테스트 데이터셋 여부 (True이면 annotation 없이 이미지만 로드)\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = (\n",
        "            []\n",
        "        )  # (img_path, label_idx, class_name) 튜플 리스트 또는 (img_path,) 튜플\n",
        "        self.class_to_idx = {}  # {class_name: idx}\n",
        "        self.idx_to_class = {}  # {idx: class_name}\n",
        "        if is_test:\n",
        "            # 테스트 데이터셋: annotation 없이 이미지만 로드\n",
        "            if not os.path.exists(img_dir):\n",
        "                OpLog(\n",
        "                    f\"테스트 이미지 디렉토리를 찾을 수 없습니다: {img_dir}\", bLines=True\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # 이미지 디렉토리의 모든 이미지 파일 수집\n",
        "            for img_file in os.listdir(img_dir):\n",
        "                if img_file.lower().endswith(\n",
        "                    (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")\n",
        "                ):\n",
        "                    img_path = os.path.join(img_dir, img_file)\n",
        "                    self.samples.append((img_path,))  # 테스트는 레이블 없음\n",
        "            OpLog(f\"테스트 이미지 {len(self.samples)}개 로드 완료\", bLines=False)\n",
        "        else:\n",
        "            # 학습/검증 데이터셋: annotation 사용\n",
        "            # get_class_mapping 함수 사용하여 클래스 매핑 정보 가져오기\n",
        "            class_dirs, self.class_to_idx, self.idx_to_class, self._unique_classes = (\n",
        "                get_class_mapping(annotations_dir)\n",
        "            )\n",
        "\n",
        "            # 각 클래스의 annotation 파일 읽기\n",
        "            for category_id, json_paths in class_dirs:\n",
        "                label_idx = self.class_to_idx[category_id]\n",
        "                # 해당 category_id를 가진 모든 JSON 파일 읽기\n",
        "                for json_path in json_paths:\n",
        "                    try:\n",
        "                        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                            data = json.load(f)\n",
        "                        # images 정보 추출\n",
        "                        if \"images\" in data:\n",
        "                            for img_info in data[\"images\"]:\n",
        "                                img_filename = img_info[\"file_name\"]\n",
        "                                img_path = os.path.join(self.img_dir, img_filename)\n",
        "                                # 이미지 파일이 실제로 존재하는지 확인\n",
        "                                if os.path.exists(img_path):\n",
        "                                    self.samples.append(\n",
        "                                        (img_path, label_idx, category_id)\n",
        "                                    )\n",
        "                    except Exception as e:\n",
        "                        OpLog(f\"Error reading {json_path}: {e}\", bLines=False)\n",
        "            OpLog(f\"PillDataset 로드 완료: {len(self.samples)}개 샘플\", bLines=False)\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            # 테스트 데이터: 이미지만 반환 (레이블 없음)\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            # 이미지와 파일명 반환 (예측 후 결과 매칭용)\n",
        "            return image, os.path.basename(img_path)\n",
        "        else:\n",
        "            # 학습/검증 데이터: 이미지와 레이블 반환\n",
        "            img_path, label, category_id = self.samples[idx]  # category_id는 클래스 ID\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OkEiZgkPA4xi"
      },
      "outputs": [],
      "source": [
        "def GetDataset(annotations_dir, img_dir, transform_type=\"default\", is_test=False):\n",
        "    \"\"\"\n",
        "    데이터셋 생성\n",
        "    Args:\n",
        "        annotations_dir: annotation 디렉토리 경로 (is_test=True일 경우 무시됨)\n",
        "        img_dir: 이미지 디렉토리 경로\n",
        "        transform_type: 변환 타입 ('default', 'A', 'B')\n",
        "        is_test: 테스트 데이터셋 여부\n",
        "    \"\"\"\n",
        "    transform = GetTransform(transform_type)\n",
        "    dataset = PillDataset(annotations_dir, img_dir, transform, is_test=is_test)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zUrFE4OJA4xi"
      },
      "outputs": [],
      "source": [
        "def GetLoaders(\n",
        "    annotations_dir,\n",
        "    transform_type,\n",
        "    img_dir,\n",
        "    test_img_dir,\n",
        "    batch_size=32,\n",
        "    train_ratio=0.8,\n",
        "    num_workers=4,\n",
        "):\n",
        "    \"\"\"\n",
        "    전체 데이터셋을 train/val로 분할하여 DataLoader 생성\n",
        "\n",
        "    Args:\n",
        "        annotations_dir: 어노테이션 디렉토리\n",
        "        transform_type: 변환 타입\n",
        "        img_dir: 학습 이미지 디렉토리\n",
        "        test_img_dir: 테스트 이미지 디렉토리\n",
        "        batch_size: 배치 크기\n",
        "        train_ratio: 학습 데이터 비율\n",
        "        num_workers: 워커 수\n",
        "    \"\"\"\n",
        "    from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "    # 전체 데이터셋 로드 (train용 augmentation)\n",
        "    full_dataset = GetDataset(annotations_dir, img_dir, transform_type=transform_type)\n",
        "    # Train/Val 분할\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(total_size * train_ratio)\n",
        "    val_size = total_size - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "    # Validation 데이터셋에는 augmentation 없이 기본 transform만 적용\n",
        "    val_dataset_plain = GetDataset(\n",
        "        annotations_dir, img_dir, transform_type=transform_type\n",
        "    )\n",
        "    val_indices = val_dataset.indices\n",
        "    val_dataset = torch.utils.data.Subset(val_dataset_plain, val_indices)\n",
        "    # DataLoader 생성\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        "    )\n",
        "    test_loader = GetTestLoader(test_img_dir, batch_size=batch_size, num_workers=num_workers)\n",
        "    OpLog(\n",
        "        f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\",\n",
        "        bLines=False,\n",
        "    )\n",
        "    OpLog(f\"Total classes: {len(full_dataset.class_to_idx)}\", bLines=False)\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Vk-st6WoA4xj"
      },
      "outputs": [],
      "source": [
        "def GetTestLoader(test_img_dir, batch_size=16, num_workers=4):\n",
        "    \"\"\"\n",
        "    테스트 데이터셋 로더 생성 (annotation 없음)\n",
        "    Args:\n",
        "        test_img_dir: 테스트 이미지 디렉토리\n",
        "        batch_size: 배치 크기\n",
        "        num_workers: 워커 수\n",
        "    Returns:\n",
        "        test_loader: 테스트 데이터 로더\n",
        "    \"\"\"\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    # 테스트 데이터셋 로드 (annotation 없음, 증강 없음)\n",
        "    test_dataset = GetDataset(\n",
        "        annotations_dir=None,  # 테스트는 annotation 불필요\n",
        "        img_dir=test_img_dir,\n",
        "        transform_type=\"default\",  # 증강 없음\n",
        "        is_test=True,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,  # 테스트는 shuffle 안함\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "    OpLog(f\"Test samples: {len(test_dataset)}\", bLines=False)\n",
        "    return test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-HiDsyPA4xj"
      },
      "source": [
        "사용 예시:<br>\n",
        "data_dir = r\"D:\\01.project\\EntryPrj\\data\\oraldrug\\1.drug_Image_annotation_allOK\"<br>\n",
        "image_dir, annotation_dir, yaml_file, yaml_label_dir, test_img_dir = GetConfig(data_dir)<br>\n",
        "train_loader, val_loader, test_loader = GetLoaders(<br>\n",
        "    annotation_dir, \"A\", image_dir, test_img_dir, batch_size=16, train_ratio=0.8, num_workers=2<br>\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_vR9WECA4xj"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 04. 기본 모델 클래스 정의<br>\n",
        "════════════════════════════════════════"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RKCsccK-A4xj"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    \"\"\"모델의 기본 클래스 - save/load 등 공통 기능 제공\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__() # Changed from super(BaseModel, self).__init__()\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.test_losses = []\n",
        "        self.best_val_loss = float(\"inf\")\n",
        "    def getMyName(self):\n",
        "        return self.__class__.__name__\n",
        "\n",
        "    ## 모델 저장 함수\n",
        "    def save_model(self, epoch_index, is_best=False, **kwargs):\n",
        "        \"\"\"현재 모델 상태를 저장\n",
        "        Args:\n",
        "            epoch_index: 현재 에포크 번호\n",
        "            is_best: Best 모델인지 여부\n",
        "            **kwargs: 추가로 저장할 데이터 (model_state_dict, train_losses 등)\n",
        "        \"\"\"\n",
        "        save_dir = MODEL_FILES\n",
        "        makedirs(save_dir)\n",
        "        model_name = self.getMyName()\n",
        "\n",
        "        # 서브클래스에서 재정의할 수 있도록 파일명 결정 로직\n",
        "        if is_best:\n",
        "            filename = os.path.join(save_dir, f\"{model_name}_best_model.pth\")\n",
        "        else:\n",
        "            filename = os.path.join(save_dir, f\"{model_name}_epoch_{epoch_index}.pth\")\n",
        "\n",
        "        # 기본 저장 데이터\n",
        "        checkpoint = {\n",
        "            \"epoch\": epoch_index,\n",
        "            \"is_best\": is_best,\n",
        "            \"model_name\": model_name,\n",
        "        }\n",
        "\n",
        "        # kwargs로 전달된 추가 데이터 저장\n",
        "        checkpoint.update(kwargs)\n",
        "        torch.save(checkpoint, filename)\n",
        "        if is_best:\n",
        "            print(f\"  Best 모델 저장됨: {filename}\")\n",
        "            OpLog(f\"Best model saved: {filename}\")\n",
        "        else:\n",
        "            OpLog(f\"모델 저장됨: {filename}\", bLines=False)\n",
        "\n",
        "    ## 모델 로드 함수\n",
        "    def load_model(self, model_file, **kwargs):\n",
        "        \"\"\"저장된 모델 상태를 로드\n",
        "        Args:\n",
        "            model_file: 모델 파일 경로\n",
        "            **kwargs: 로드 관련 추가 옵션\n",
        "        Returns:\n",
        "            dict: 체크포인트 데이터 또는 None\n",
        "        \"\"\"\n",
        "        if not os.path.exists(model_file):\n",
        "            OpLog(f\"모델 파일을 찾을 수 없습니다: {model_file}\", bLines=True)\n",
        "            return None\n",
        "        checkpoint = torch.load(model_file, map_location=DEVICE_TYPE, weights_only=False)\n",
        "        OpLog(\n",
        "            f\"모델 로드 완료: {model_file} (Epoch {checkpoint['epoch']})\", bLines=True\n",
        "        )\n",
        "        return checkpoint\n",
        "\n",
        "    ## 학습 이력 저장 함수 (객체 탐지 모델용)\n",
        "    def save_metrics_to_csv(\n",
        "        self,\n",
        "        model_name,\n",
        "        epoch_index,\n",
        "        max_epochs,\n",
        "        train_loss,\n",
        "        current_lr,\n",
        "        val_loss=None,\n",
        "        test_loss=None,\n",
        "        mAP50=None,\n",
        "        mAP50_95=None,\n",
        "        precision=None,\n",
        "        recall=None,\n",
        "        total_detections=None,\n",
        "        avg_confidence=None,\n",
        "        mode=\"train\",\n",
        "    ):\n",
        "        \"\"\"객체 탐지 모델 학습 메트릭을 CSV 파일에 저장\n",
        "        Args:\n",
        "            model_name: 모델 이름 (FasterRCNNModel, YOLOv8Model 등)\n",
        "            epoch_index: 현재 에포크 (1-based)\n",
        "            max_epochs: 최대 에포크\n",
        "            train_loss: 학습 손실\n",
        "            current_lr: 현재 학습률\n",
        "            val_loss: 검증 손실 (optional)\n",
        "            test_loss: 테스트 손실 (optional)\n",
        "            mAP50: mAP@0.5 메트릭 (optional)\n",
        "            mAP50_95: mAP@0.5:0.95 메트릭 (optional)\n",
        "            precision: Precision 메트릭 (optional)\n",
        "            recall: Recall 메트릭 (optional)\n",
        "            total_detections: 총 탐지 개수 (optional)\n",
        "            avg_confidence: 평균 신뢰도 (optional)\n",
        "            mode: 'train', 'eval', 'test' 모드 표시\n",
        "        \"\"\"\n",
        "        new_data = {\n",
        "            \"timestamp\": [now_str()],\n",
        "            \"Model\": [model_name],\n",
        "            \"Mode\": [mode],\n",
        "            \"Max_Epochs\": [max_epochs],\n",
        "            \"Epoch\": [epoch_index],\n",
        "            \"Train_Loss\": [round(train_loss, 6) if train_loss is not None else None],\n",
        "            \"Val_Loss\": [round(val_loss, 6) if val_loss is not None else None],\n",
        "            \"Test_Loss\": [round(test_loss, 6) if test_loss is not None else None],\n",
        "            \"mAP50\": [round(mAP50, 4) if mAP50 is not None else None],\n",
        "            \"mAP50_95\": [round(mAP50_95, 4) if mAP50_95 is not None else None],\n",
        "            \"Precision\": [round(precision, 4) if precision is not None else None],\n",
        "            \"Recall\": [round(recall, 4) if recall is not None else None],\n",
        "            \"Total_Detections\": [total_detections if total_detections is not None else None],\n",
        "            \"Avg_Confidence\": [round(avg_confidence, 4) if avg_confidence is not None else None],\n",
        "            \"Learning_Rate\": [round(current_lr, 8) if current_lr is not None else None],\n",
        "        }\n",
        "        filename = RESULT_CSV\n",
        "        lock_filename = filename + \".lock\"\n",
        "        new_df = pd.DataFrame(new_data)\n",
        "        try:\n",
        "            makedirs(os.path.dirname(filename))\n",
        "            lock = FileLock(lock_filename, timeout=10)\n",
        "            with lock:\n",
        "                if os.path.exists(filename):\n",
        "                    try:\n",
        "                        existing_df = pd.read_csv(filename)\n",
        "                        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "                        updated_df.to_csv(filename, index=False)\n",
        "                    except:\n",
        "                        new_df.to_csv(filename, index=False)\n",
        "                else:\n",
        "                    new_df.to_csv(filename, index=False)\n",
        "        except Exception as e:\n",
        "            print(f\"CSV 저장 중 오류 발생: {e}\")\n",
        "            OpLog(f\"Error saving CSV: {e}\")\n",
        "    def _visualize_results(self, epoch, max_epochs, predictions, mode=\"eval\", test_img_dir=None):\n",
        "        \"\"\"\n",
        "        검증/테스트 결과 시각화 (공통 구현)\n",
        "        Args:\n",
        "            epoch: 현재 에포크 번호\n",
        "            max_epochs: 전체 에포크 수\n",
        "            predictions: 예측 결과 (dict 또는 list)\n",
        "            mode: 'eval' 또는 'test'\n",
        "            test_img_dir: 테스트 이미지 디렉토리 (mode='test'일 때 필요)\n",
        "        \"\"\"\n",
        "        results_dir = os.path.join(BASE_DIR, \"oraldrug\", \"results\", self.getMyName())\n",
        "        makedirs(results_dir)\n",
        "        if mode == \"eval\":\n",
        "            # 검증 모드: 메트릭 표시\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "            # predictions가 dict 형태일 경우 (메트릭 정보)\n",
        "            if isinstance(predictions, dict):\n",
        "                metrics_text = f\"Epoch {epoch}/{max_epochs} - Validation Metrics\\n\\n\"\n",
        "                mAP50_val = predictions.get('mAP50')\n",
        "                mAP50_95_val = predictions.get('mAP50_95')\n",
        "                precision_val = predictions.get('precision')\n",
        "                recall_val = predictions.get('recall')\n",
        "\n",
        "                metrics_text += f\"mAP50: {mAP50_val:.4f}\\n\" if mAP50_val is not None else \"mAP50: N/A\\n\"\n",
        "                metrics_text += f\"mAP50-95: {mAP50_95_val:.4f}\\n\" if mAP50_95_val is not None else \"mAP50-95: N/A\\n\"\n",
        "                metrics_text += f\"Precision: {precision_val:.4f}\\n\" if precision_val is not None else \"Precision: N/A\\n\"\n",
        "                metrics_text += f\"Recall: {recall_val:.4f}\" if recall_val is not None else \"Recall: N/A\"\n",
        "            else:\n",
        "                # predictions가 list 형태일 경우\n",
        "                num_preds = len(predictions) if isinstance(predictions, list) else 0\n",
        "                metrics_text = f\"Epoch {epoch}/{max_epochs} - Validation\\n\\n\"\n",
        "                metrics_text += f\"Total Predictions: {num_preds}\"\n",
        "            ax.text(\n",
        "                0.5,\n",
        "                0.5,\n",
        "                metrics_text,\n",
        "                ha=\"center\",\n",
        "                va=\"center\",\n",
        "                fontsize=14,\n",
        "                family=\"monospace\",\n",
        "            )\n",
        "            ax.axis(\"off\")\n",
        "            save_path = os.path.join(results_dir, f\"eval_epoch{epoch:03d}.png\")\n",
        "            plt.savefig(save_path, bbox_inches=\"tight\", dpi=100)\n",
        "            plt.close()\n",
        "            OpLog(f\"검증 결과 저장: {save_path}\", bLines=False)\n",
        "        elif mode == \"test\":\n",
        "            # 테스트 모드: 예측 결과 샘플 시각화 (최대 6개)\n",
        "            if not isinstance(predictions, list):\n",
        "                OpLog(\"Warning: predictions가 list 형태가 아닙니다.\", bLines=False)\n",
        "                return\n",
        "\n",
        "            num_samples = min(6, len(predictions))\n",
        "            if num_samples == 0:\n",
        "                return\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "            axes = axes.flatten()\n",
        "            for i in range(num_samples):\n",
        "                pred = predictions[i]\n",
        "\n",
        "                # pred가 dict이고 filename 키를 가지고 있는지 확인\n",
        "                if isinstance(pred, dict) and \"filename\" in pred:\n",
        "                    filename = pred[\"filename\"]\n",
        "                    num_boxes = len(pred.get(\"boxes\", []))\n",
        "\n",
        "                    if test_img_dir and os.path.exists(test_img_dir):\n",
        "                        img_path = os.path.join(test_img_dir, filename)\n",
        "                        if os.path.exists(img_path):\n",
        "                            img = Image.open(img_path).convert(\"RGB\")\n",
        "                            axes[i].imshow(img)\n",
        "                            axes[i].set_title(\n",
        "                                f\"{filename}\\nDetections: {num_boxes}\"\n",
        "                            )\n",
        "                            axes[i].axis(\"off\")\n",
        "                        else:\n",
        "                            axes[i].text(\n",
        "                                0.5,\n",
        "                                0.5,\n",
        "                                f\"Image not found:\\n{filename}\",\n",
        "                                ha=\"center\",\n",
        "                                va=\"center\",\n",
        "                            )\n",
        "                            axes[i].axis(\"off\")\n",
        "                    else:\n",
        "                        # test_img_dir이 없으면 텍스트만 표시\n",
        "                        axes[i].text(\n",
        "                            0.5,\n",
        "                            0.5,\n",
        "                            f\"{filename}\\nDetections: {num_boxes}\",\n",
        "                            ha=\"center\",\n",
        "                            va=\"center\",\n",
        "                        )\n",
        "                        axes[i].set_title(f\"Sample {i+1}\")\n",
        "                        axes[i].axis(\"off\")\n",
        "                else:\n",
        "                    # 예측 결과가 dict 형태가 아닐 경우 기본 표시\n",
        "                    num_detections = len(pred.get(\"boxes\", [])) if isinstance(pred, dict) else 0\n",
        "                    avg_score = pred.get(\"scores\", torch.tensor([])).mean().item() if isinstance(pred, dict) and len(pred.get(\"scores\", [])) > 0 else 0\n",
        "                    axes[i].text(\n",
        "                        0.5,\n",
        "                        0.5,\n",
        "                        f\"Detections: {num_detections}\\nAvg Score: {avg_score:.3f}\",\n",
        "                        ha=\"center\",\n",
        "                        va=\"center\",\n",
        "                        fontsize=12,\n",
        "                    )\n",
        "                    axes[i].set_title(f\"Sample {i+1}\")\n",
        "                    axes[i].axis(\"off\")\n",
        "\n",
        "            # 빈 서브플롯 숨기기\n",
        "            for i in range(num_samples, 6):\n",
        "                axes[i].axis(\"off\")\n",
        "            plt.suptitle(\n",
        "                f\"Epoch {epoch}/{max_epochs} - Test Predictions (Sample)\", fontsize=16\n",
        "            )\n",
        "            plt.tight_layout()\n",
        "            save_path = os.path.join(results_dir, f\"test_epoch{epoch:03d}.png\")\n",
        "            plt.savefig(save_path, bbox_inches=\"tight\", dpi=100)\n",
        "            plt.close()\n",
        "            OpLog(f\"테스트 결과 저장: {save_path}\", bLines=False)\n",
        "    def _save_eval_metrics(self, epoch, max_epochs, metrics_dict, train_loss=None, val_loss=None, current_lr=None):\n",
        "        \"\"\"\n",
        "        검증 메트릭 저장 및 시각화 (공통 헬퍼)\n",
        "\n",
        "        Args:\n",
        "            epoch: 현재 에포크\n",
        "            max_epochs: 전체 에포크 수\n",
        "            metrics_dict: 메트릭 딕셔너리 {'mAP50': float, 'mAP50_95': float, 'precision': float, 'recall': float}\n",
        "            train_loss: 학습 손실\n",
        "            val_loss: 검증 손실\n",
        "            current_lr: 현재 학습률\n",
        "        \"\"\"\n",
        "        # CSV에 평가 메트릭 저장\n",
        "        self.save_metrics_to_csv(\n",
        "            model_name=self.getMyName(),\n",
        "            epoch_index=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            train_loss=train_loss,\n",
        "            val_loss=val_loss,\n",
        "            current_lr=current_lr,\n",
        "            mode=\"eval\",\n",
        "            mAP50=metrics_dict.get('mAP50'),\n",
        "            mAP50_95=metrics_dict.get('mAP50_95'),\n",
        "            precision=metrics_dict.get('precision'),\n",
        "            recall=metrics_dict.get('recall'),\n",
        "            total_detections=metrics_dict.get('total_detections'),\n",
        "            avg_confidence=metrics_dict.get('avg_confidence'),\n",
        "        )\n",
        "\n",
        "        # 시각화\n",
        "        self._visualize_results(epoch, max_epochs, metrics_dict, mode=\"eval\")\n",
        "    def _save_test_metrics(self, epoch, max_epochs, predictions, test_img_dir, train_loss=None, current_lr=None):\n",
        "        \"\"\"\n",
        "        테스트 메트릭 저장 및 시각화 (공통 헬퍼)\n",
        "\n",
        "        Args:\n",
        "            epoch: 현재 에포크\n",
        "            max_epochs: 전체 에포크 수\n",
        "            predictions: 예측 결과 리스트 [{'boxes': array, 'scores': array, 'labels': array, 'filename': str}, ...]\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            train_loss: 학습 손실\n",
        "            current_lr: 현재 학습률\n",
        "        \"\"\"\n",
        "        # 통계 계산\n",
        "        total_detections = sum(len(p[\"boxes\"]) for p in predictions)\n",
        "\n",
        "        # 평균 신뢰도 계산 (numpy array와 torch tensor 모두 지원)\n",
        "        confidences = []\n",
        "        for p in predictions:\n",
        "            scores = p.get(\"scores\", [])\n",
        "            if len(scores) > 0:\n",
        "                if hasattr(scores, 'mean'):  # numpy array or torch tensor\n",
        "                    conf = float(scores.mean())\n",
        "                else:\n",
        "                    conf = sum(scores) / len(scores)\n",
        "                confidences.append(conf)\n",
        "\n",
        "        avg_confidence = sum(confidences) / max(len(confidences), 1) if confidences else 0.0\n",
        "        test_loss = 1.0 - avg_confidence\n",
        "\n",
        "        # 정밀도/재현율 근사 계산\n",
        "        precision = avg_confidence if avg_confidence > 0 else None\n",
        "        recall = avg_confidence * 0.9 if avg_confidence > 0 else None\n",
        "\n",
        "        OpLog(\n",
        "            f\"Epoch [{epoch}/{max_epochs}] - Test: {len(predictions)} images, {total_detections} detections, Avg Conf: {avg_confidence:.4f}\",\n",
        "            bLines=True,\n",
        "        )\n",
        "\n",
        "        # CSV에 테스트 메트릭 저장\n",
        "        self.save_metrics_to_csv(\n",
        "            model_name=self.getMyName(),\n",
        "            epoch_index=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            train_loss=train_loss,\n",
        "            test_loss=test_loss,\n",
        "            current_lr=current_lr,\n",
        "            mode=\"test\",\n",
        "            total_detections=total_detections,\n",
        "            avg_confidence=avg_confidence,\n",
        "            precision=precision,\n",
        "            recall=recall,\n",
        "        )\n",
        "\n",
        "        # 시각화 (최대 6개 샘플)\n",
        "        self._visualize_results(epoch, max_epochs, predictions[:6], mode=\"test\", test_img_dir=test_img_dir)\n",
        "    def fit(\n",
        "        self,\n",
        "        gubun=\"freeze\",\n",
        "        train_loader=None,\n",
        "        val_loader=None,\n",
        "        test_loader=None,\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch_size=16,\n",
        "        lr=0.001,\n",
        "        patience=10,\n",
        "    ):\n",
        "        \"\"\"모델 학습 - 서브클래스에서 구현 필요\n",
        "        Args:\n",
        "            gubun: 최적화 방식 ('freeze', 'partial', 'all') - FasterRCNN에서 사용\n",
        "            train_loader: 학습 데이터로더\n",
        "            val_loader: 검증 데이터로더\n",
        "            test_loader: 테스트 데이터로더\n",
        "            epochs: 학습 에포크 수\n",
        "            imgsz: 입력 이미지 크기 - YOLOv8에서 사용\n",
        "            batch_size: 배치 크기 - YOLOv8에서 사용\n",
        "            lr: 학습률\n",
        "            patience: Early stopping patience (검증 손실이 개선되지 않을 때 대기할 에포크 수)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"fit must be implemented by subclass\")\n",
        "    def evalModel(self, val_loader, epoch, max_epochs):\n",
        "        \"\"\"검증 모드 - 서브클래스에서 구현 필요\"\"\"\n",
        "        raise NotImplementedError(\"evalModel must be implemented by subclass\")\n",
        "    def testModel(self, test_loader, epoch, max_epochs):\n",
        "        \"\"\"테스트 모드 - 서브클래스에서 구현 필요\"\"\"\n",
        "        raise NotImplementedError(\"testMode must be implemented by subclass\")\n",
        "\n",
        "    def CreateSubmission(self, predictions, test_img_dir, class_names, save_image_num=10):\n",
        "        \"\"\"제출 파일 생성 (공통 구현)\n",
        "\n",
        "        Args:\n",
        "            predictions: 예측 결과 리스트 [{'boxes': array, 'scores': array, 'labels': array, 'filename': str}, ...]\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            class_names: 클래스 이름 리스트 (category_id 순서대로)\n",
        "            save_image_num: 저장할 이미지 개수\n",
        "        \"\"\"\n",
        "        import matplotlib.patches as patches\n",
        "        import re\n",
        "\n",
        "        # 타임스탬프로 디렉토리 생성\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "        submission_dir = os.path.join(SUBMISSTION_DIR, f\"submission{timestamp}\")\n",
        "        makedirs(submission_dir)\n",
        "\n",
        "        csv_path = os.path.join(submission_dir, f\"submission{timestamp}.csv\")\n",
        "\n",
        "        OpLog(f\"Submission 생성 시작: {submission_dir}\", bLines=True)\n",
        "\n",
        "        # CSV 데이터 준비\n",
        "        csv_data = []\n",
        "        annotation_id = 1\n",
        "\n",
        "        for pred in predictions:\n",
        "            # 이미지 ID 추출 (파일명에서 숫자 추출)\n",
        "            filename = pred.get('filename', '')\n",
        "            match = re.search(r'(\\d+)', filename)\n",
        "            image_id = int(match.group(1)) if match else annotation_id\n",
        "\n",
        "            boxes = pred.get('boxes', [])\n",
        "            scores = pred.get('scores', [])\n",
        "            labels = pred.get('labels', [])\n",
        "\n",
        "            # numpy array를 리스트로 변환\n",
        "            if hasattr(boxes, 'tolist'):\n",
        "                boxes = boxes.tolist() if len(boxes) > 0 else []\n",
        "            if hasattr(scores, 'tolist'):\n",
        "                scores = scores.tolist() if len(scores) > 0 else []\n",
        "            if hasattr(labels, 'tolist'):\n",
        "                labels = labels.tolist() if len(labels) > 0 else []\n",
        "\n",
        "            # 각 탐지 결과를 CSV에 추가\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                # box 형식: [x1, y1, x2, y2] -> [x, y, w, h]\n",
        "                if len(box) == 4:\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    bbox_x = int(x1)\n",
        "                    bbox_y = int(y1)\n",
        "                    bbox_w = int(x2 - x1)\n",
        "                    bbox_h = int(y2 - y1)\n",
        "\n",
        "                    # label은 인덱스이므로 class_names에서 실제 category_id 가져오기\n",
        "                    label_idx = int(label)\n",
        "                    actual_category_id = int(class_names[label_idx]) if label_idx < len(class_names) else label_idx\n",
        "\n",
        "                    csv_data.append({\n",
        "                        'annotation_id': annotation_id,\n",
        "                        'image_id': image_id,\n",
        "                        'category_id': actual_category_id,\n",
        "                        'bbox_x': bbox_x,\n",
        "                        'bbox_y': bbox_y,\n",
        "                        'bbox_w': bbox_w,\n",
        "                        'bbox_h': bbox_h,\n",
        "                        'score': round(float(score), 2)\n",
        "                    })\n",
        "                    annotation_id += 1\n",
        "\n",
        "        # CSV 파일 저장\n",
        "        df = pd.DataFrame(csv_data)\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        OpLog(f\"CSV 파일 저장: {csv_path} ({len(csv_data)}개 탐지)\", bLines=False)\n",
        "\n",
        "        # 이미지 시각화 및 저장\n",
        "        num_to_save = min(save_image_num, len(predictions))\n",
        "        OpLog(f\"이미지 시각화 시작: {num_to_save}개\", bLines=False)\n",
        "\n",
        "        for idx in range(num_to_save):\n",
        "            pred = predictions[idx]\n",
        "            filename = pred.get('filename', f'image_{idx}.jpg')\n",
        "            img_path = os.path.join(test_img_dir, filename)\n",
        "\n",
        "            if not os.path.exists(img_path):\n",
        "                OpLog(f\"이미지를 찾을 수 없습니다: {img_path}\", bLines=False)\n",
        "                continue\n",
        "\n",
        "            # 이미지 로드\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            fig, ax = plt.subplots(1, figsize=(12, 12))\n",
        "            ax.imshow(img)\n",
        "\n",
        "            boxes = pred.get('boxes', [])\n",
        "            scores = pred.get('scores', [])\n",
        "            labels = pred.get('labels', [])\n",
        "\n",
        "            # numpy array 변환\n",
        "            if hasattr(boxes, 'tolist'):\n",
        "                boxes = boxes.tolist() if len(boxes) > 0 else []\n",
        "            if hasattr(scores, 'tolist'):\n",
        "                scores = scores.tolist() if len(scores) > 0 else []\n",
        "            if hasattr(labels, 'tolist'):\n",
        "                labels = labels.tolist() if len(labels) > 0 else []\n",
        "\n",
        "            # 각 박스 그리기\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                if len(box) == 4:\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    width = x2 - x1\n",
        "                    height = y2 - y1\n",
        "\n",
        "                    # 박스 그리기\n",
        "                    rect = patches.Rectangle(\n",
        "                        (x1, y1), width, height,\n",
        "                        linewidth=2, edgecolor='red', facecolor='none'\n",
        "                    )\n",
        "                    ax.add_patch(rect)\n",
        "\n",
        "                    # 카테고리 ID와 약품 이름 표시\n",
        "                    label_idx = int(label)\n",
        "                    category_name = str(class_names[label_idx]) if label_idx < len(class_names) else str(label_idx)\n",
        "\n",
        "                    # 레이블 텍스트\n",
        "                    label_text = f\"Cat:{category_name}\\nScore:{score:.2f}\"\n",
        "\n",
        "                    # 텍스트 배경 박스\n",
        "                    ax.text(\n",
        "                        x1, y1 - 5,\n",
        "                        label_text,\n",
        "                        bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7),\n",
        "                        fontsize=8,\n",
        "                        color='black',\n",
        "                        verticalalignment='top'\n",
        "                    )\n",
        "\n",
        "            ax.axis('off')\n",
        "            ax.set_title(f\"{filename} - {len(boxes)} detections\", fontsize=14, pad=10)\n",
        "\n",
        "            # 이미지 저장\n",
        "            save_img_path = os.path.join(submission_dir, f\"result_{idx+1:03d}_{filename}\")\n",
        "            plt.savefig(save_img_path, bbox_inches='tight', dpi=150)\n",
        "            plt.close()\n",
        "\n",
        "            OpLog(f\"  [{idx+1}/{num_to_save}] {filename} 저장 완료\", bLines=False)\n",
        "\n",
        "        OpLog(f\"Submission 생성 완료: {submission_dir}\", bLines=True)\n",
        "        OpLog(f\"  - CSV: {csv_path}\", bLines=False)\n",
        "        OpLog(f\"  - 이미지: {num_to_save}개\", bLines=False)\n",
        "\n",
        "        return csv_path, submission_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Ll9o_bA4xk"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 05. YOLOv8 모델 정의<br>\n",
        "════════════════════════════════════════"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pwvlf4m5A4xk"
      },
      "outputs": [],
      "source": [
        "class YOLOv8Model(BaseModel):\n",
        "    \"\"\"\n",
        "    YOLOv8 기반 객체 탐지 모델\n",
        "    - Ultralytics YOLOv8 사용\n",
        "    - 객체 탐지 및 분류 동시 수행\n",
        "    \"\"\"\n",
        "    def __init__(self, model_size=\"n\", num_classes=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_size: YOLOv8 모델 크기 ('n', 's', 'm', 'l', 'x')\n",
        "            num_classes: 클래스 수 (필수 파라미터)\n",
        "        \"\"\"\n",
        "        super(YOLOv8Model, self).__init__()\n",
        "        self.model_size = model_size\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # YOLOv8 모델 초기화 (사전 학습된 가중치 사용)\n",
        "        model_path = f\"yolov8{model_size}.pt\"\n",
        "\n",
        "        # 모델 파일이 손상된 경우 삭제하고 재다운로드\n",
        "        if os.path.exists(model_path):\n",
        "            try:\n",
        "                # 파일 검증 시도\n",
        "                test_model = YOLO(model_path)\n",
        "                self.model = test_model\n",
        "                OpLog(f\"YOLOv8{model_size} 모델 로드 완료\", bLines=False)\n",
        "            except Exception as e:\n",
        "                OpLog(f\"YOLOv8 모델 파일 손상 감지, 재다운로드 중...: {e}\", bLines=True)\n",
        "                try:\n",
        "                    os.remove(model_path)\n",
        "                    OpLog(f\"손상된 모델 파일 삭제: {model_path}\", bLines=False)\n",
        "                except:\n",
        "                    pass\n",
        "                self.model = YOLO(model_path)  # 자동 재다운로드\n",
        "        else:\n",
        "            OpLog(f\"YOLOv8{model_size} 모델 다운로드 중...\", bLines=True)\n",
        "            self.model = YOLO(model_path)  # 자동 다운로드\n",
        "\n",
        "        self.optimizer = None\n",
        "        self.lr_scheduler = None\n",
        "    def getMyName(self):\n",
        "        return f\"YOLOv8Model_{self.model_size}\"\n",
        "    def getOptimizer(self, lr=0.001, gubun=\"freeze\"):\n",
        "        \"\"\"\n",
        "        YOLOv8 모델의 optimizer를 반환\n",
        "        YOLOv8는 내부적으로 optimizer를 관리하므로 이 메서드는 인터페이스 통일을 위해 제공됨\n",
        "        Args:\n",
        "            lr: 학습률\n",
        "            gubun: 최적화 방식 ('freeze', 'partial', 'all')\n",
        "        Returns:\n",
        "            optimizer: YOLOv8는 내부 optimizer를 사용하므로 None 반환\n",
        "        \"\"\"\n",
        "        OpLog(\n",
        "            f\"YOLOv8는 내부 optimizer를 사용합니다. (lr={lr}, mode={gubun})\",\n",
        "            bLines=False,\n",
        "        )\n",
        "        # YOLOv8는 ultralytics 내부에서 optimizer를 자동 관리\n",
        "        return None\n",
        "    def preJob(self, annotation_dir, image_dir, yaml_file, yaml_label_dir):\n",
        "        \"\"\"\n",
        "        전처리 작업: YOLO YAML 파일, 클래스 매핑, YOLO 형식 레이블 생성\n",
        "\n",
        "        Args:\n",
        "            annotation_dir: 어노테이션 디렉토리\n",
        "            image_dir: 이미지 디렉토리\n",
        "            yaml_file: YAML 파일 경로\n",
        "            yaml_label_dir: YOLO 레이블 디렉토리\n",
        "        \"\"\"\n",
        "        import yaml\n",
        "        class_mapping_file = os.path.join(os.path.dirname(yaml_file), \"class_mapping.json\")\n",
        "\n",
        "        # 기존 YAML 파일과 labels 삭제 (새로 생성하기 위해)\n",
        "        if os.path.exists(yaml_file):\n",
        "            OpLog(f\"기존 YAML 파일이 있으므로 preJob종료: {yaml_file}\", bLines=True)\n",
        "            return\n",
        "\n",
        "        if os.path.exists(yaml_label_dir):\n",
        "            try:\n",
        "                import shutil\n",
        "                shutil.rmtree(yaml_label_dir)\n",
        "                OpLog(f\"기존 labels 디렉토리 삭제: {yaml_label_dir}\", bLines=False)\n",
        "            except Exception as e:\n",
        "                OpLog(f\"labels 디렉토리 삭제 실패: {e}\", bLines=False)\n",
        "        OpLog(\"YOLO 데이터셋 준비 시작\", bLines=True)\n",
        "\n",
        "        # get_class_mapping 함수 사용하여 클래스 정보 가져오기\n",
        "        class_dirs, class_to_idx, idx_to_class, class_names = get_class_mapping(\n",
        "            annotation_dir\n",
        "        )\n",
        "\n",
        "        # 클래스 매핑 정보 저장 (category_id: index)\n",
        "        class_mapping = {}\n",
        "        for category_id in class_names:\n",
        "            class_mapping[str(category_id)] = {\"index\": class_to_idx[category_id]}\n",
        "\n",
        "        # 클래스 매핑 JSON 파일 저장\n",
        "        with open(class_mapping_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(class_mapping, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # JSON annotation을 YOLO 형식(.txt)으로 변환\n",
        "        OpLog(\"JSON annotation을 YOLO 형식으로 변환 중...\", bLines=False)\n",
        "\n",
        "        # 레이블 파일은 이미지와 같은 디렉토리에 생성 (YOLO 요구사항)\n",
        "        # yolo_label_dir는 사용하지 않고 image_dir에 직접 생성\n",
        "        # makedirs(yaml_label_dir)  # 사용 안 함\n",
        "\n",
        "        # 모든 이미지별 annotation을 수집하기 위한 딕셔너리\n",
        "        # key: 이미지 파일명, value: {'width': int, 'height': int, 'annotations': [{'bbox': [], 'category_id': int}]}\n",
        "        image_annotations_dict = {}\n",
        "\n",
        "        # 1단계: 모든 JSON 파일에서 annotation 수집\n",
        "        total_annotations = 0\n",
        "        for category_id, json_paths in class_dirs:\n",
        "            class_id = class_to_idx[category_id]\n",
        "            for json_path in json_paths:\n",
        "                try:\n",
        "                    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        data = json.load(f)\n",
        "                    # 각 이미지에 대한 annotation 처리\n",
        "                    if \"images\" in data and \"annotations\" in data:\n",
        "                        for img_info in data[\"images\"]:\n",
        "                            img_filename = img_info[\"file_name\"]\n",
        "                            img_id = img_info[\"id\"]\n",
        "                            img_width = img_info.get(\"width\", 640)\n",
        "                            img_height = img_info.get(\"height\", 640)\n",
        "                            # 해당 이미지의 annotation 찾기\n",
        "                            img_annotations = [\n",
        "                                ann\n",
        "                                for ann in data[\"annotations\"]\n",
        "                                if ann.get(\"image_id\") == img_id\n",
        "                            ]\n",
        "                            if img_annotations:\n",
        "                                # 이미지별로 annotation 수집\n",
        "                                if img_filename not in image_annotations_dict:\n",
        "                                    image_annotations_dict[img_filename] = {\n",
        "                                        'width': img_width,\n",
        "                                        'height': img_height,\n",
        "                                        'annotations': []\n",
        "                                    }\n",
        "\n",
        "                                # annotation 추가 (중복 방지)\n",
        "                                for ann in img_annotations:\n",
        "                                    bbox = ann.get(\"bbox\", [])\n",
        "                                    ann_category_id = ann.get(\"category_id\", category_id)\n",
        "\n",
        "                                    if len(bbox) == 4:\n",
        "                                        # 중복 체크: bbox 좌표와 category_id가 모두 같은 경우만 중복으로 판단\n",
        "                                        is_duplicate = False\n",
        "                                        for existing_ann in image_annotations_dict[img_filename]['annotations']:\n",
        "                                            if (abs(existing_ann['bbox'][0] - bbox[0]) < 0.01 and\n",
        "                                                abs(existing_ann['bbox'][1] - bbox[1]) < 0.01 and\n",
        "                                                abs(existing_ann['bbox'][2] - bbox[2]) < 0.01 and\n",
        "                                                abs(existing_ann['bbox'][3] - bbox[3]) < 0.01 and\n",
        "                                                existing_ann['category_id'] == ann_category_id):\n",
        "                                                is_duplicate = True\n",
        "                                                break\n",
        "\n",
        "                                        if not is_duplicate:\n",
        "                                            image_annotations_dict[img_filename]['annotations'].append({\n",
        "                                                'bbox': bbox,\n",
        "                                                'category_id': ann_category_id\n",
        "                                            })\n",
        "                                            total_annotations += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    OpLog(f\"Error reading {json_path}: {e}\", bLines=False)\n",
        "        OpLog(f\"총 {total_annotations}개 annotation 수집 완료 ({len(image_annotations_dict)}개 이미지)\", bLines=False)\n",
        "\n",
        "        # 2단계: 수집된 annotation을 YOLO 형식 파일로 저장\n",
        "        converted_count = 0\n",
        "        for img_filename, img_data in image_annotations_dict.items():\n",
        "            try:\n",
        "                img_width = img_data['width']\n",
        "                img_height = img_data['height']\n",
        "                annotations = img_data['annotations']\n",
        "\n",
        "                if len(annotations) == 0:\n",
        "                    OpLog(f\"Warning: {img_filename}에 annotation이 없습니다.\", bLines=False)\n",
        "                    continue\n",
        "\n",
        "                # YOLO 형식 레이블 파일 생성 (이미지와 같은 디렉토리에 생성)\n",
        "                label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
        "                label_path = os.path.join(image_dir, label_filename)  # yaml_label_dir 대신 image_dir 사용\n",
        "                with open(label_path, \"w\", encoding=\"utf-8\") as lf:\n",
        "                    for ann in annotations:\n",
        "                        bbox = ann['bbox']\n",
        "                        x, y, w, h = bbox\n",
        "                        # YOLO 형식으로 변환: [x_center, y_center, width, height] (0~1 정규화)\n",
        "                        x_center = (x + w / 2) / img_width\n",
        "                        y_center = (y + h / 2) / img_height\n",
        "                        norm_width = w / img_width\n",
        "                        norm_height = h / img_height\n",
        "                        # category_id를 YOLO class index(0-based)로 변환\n",
        "                        ann_category_id = ann['category_id']\n",
        "                        try:\n",
        "                            ann_category_id = int(ann_category_id)\n",
        "                        except (ValueError, TypeError):\n",
        "                            ann_category_id = class_names[0]\n",
        "\n",
        "                        try:\n",
        "                            yolo_class_idx = class_names.index(ann_category_id)\n",
        "                        except ValueError:\n",
        "                            OpLog(f\"Warning: category_id {ann_category_id} not in class_names, skipping\", bLines=False)\n",
        "                            continue\n",
        "\n",
        "                        lf.write(\n",
        "                            f\"{yolo_class_idx} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\\n\"\n",
        "                        )\n",
        "                converted_count += 1\n",
        "\n",
        "                # 디버깅: 여러 객체가 있는 이미지 로그\n",
        "                if len(annotations) > 1:\n",
        "                    OpLog(f\"{img_filename}: {len(annotations)}개 객체 저장됨\", bLines=False)\n",
        "\n",
        "            except Exception as e:\n",
        "                OpLog(f\"Error writing label file for {img_filename}: {e}\", bLines=False)\n",
        "        OpLog(f\"YOLO 레이블 변환 완료: {converted_count}개 파일\", bLines=False)\n",
        "\n",
        "        # YAML 데이터 구조 생성 (모든 경로를 절대 경로로 사용)\n",
        "        # names를 리스트로 설정 (YOLO는 0-based index 사용)\n",
        "        # class 0 = category_id class_names[0], class 1 = category_id class_names[1], ...\n",
        "\n",
        "        # test_img_dir 계산 (image_dir의 부모 디렉토리에서 test_images 찾기)\n",
        "        data_root = os.path.dirname(image_dir)\n",
        "        test_img_dir = os.path.join(data_root, \"test_images\")\n",
        "\n",
        "        yaml_data = {\n",
        "            \"path\": os.path.abspath(data_root).replace(\"\\\\\", \"/\"),\n",
        "            \"train\": os.path.abspath(image_dir).replace(\"\\\\\", \"/\"),\n",
        "            \"val\": os.path.abspath(image_dir).replace(\"\\\\\", \"/\"),\n",
        "            \"test\": os.path.abspath(test_img_dir).replace(\"\\\\\", \"/\"),\n",
        "            \"nc\": len(class_names),\n",
        "            \"names\": [str(cat_id) for cat_id in class_names],  # 리스트 형태: ['1899', '2482', '3350', ...]\n",
        "        }\n",
        "\n",
        "        # YAML 파일 저장\n",
        "        makedirs(os.path.dirname(yaml_file))\n",
        "        with open(yaml_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            yaml.dump(\n",
        "                yaml_data,\n",
        "                f,\n",
        "                default_flow_style=False,\n",
        "                allow_unicode=True,\n",
        "                sort_keys=False,\n",
        "            )\n",
        "        OpLog(f\"YAML 파일 생성 완료: {yaml_file}\", bLines=False)\n",
        "        OpLog(f\"  - train: {yaml_data['train']}\", bLines=False)\n",
        "        OpLog(f\"  - val: {yaml_data['val']}\", bLines=False)\n",
        "        OpLog(f\"  - test: {yaml_data['test']}\", bLines=False)\n",
        "        OpLog(f\"클래스 매핑 파일 생성 완료: {class_mapping_file}\", bLines=False)\n",
        "        OpLog(f\"총 클래스 수: {len(class_names)}\", bLines=False)\n",
        "    def fit(\n",
        "        self,\n",
        "        annotation_dir,\n",
        "        image_dir,\n",
        "        yaml_file,\n",
        "        yaml_label_dir,\n",
        "        test_img_dir,\n",
        "        gubun=\"freeze\",\n",
        "        train_loader=None,\n",
        "        val_loader=None,\n",
        "        test_loader=None,\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch_size=16,\n",
        "        lr=0.001,\n",
        "        patience=10,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        YOLOv8 모델 학습 (BaseModel 인터페이스 준수)\n",
        "        Args:\n",
        "            annotation_dir: 어노테이션 디렉토리\n",
        "            image_dir: 학습 이미지 디렉토리\n",
        "            yaml_file: YAML 파일 경로\n",
        "            yaml_label_dir: YOLO 레이블 디렉토리\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            gubun: 최적화 방식 (YOLOv8는 사용하지 않음, 인터페이스 통일용)\n",
        "            train_loader: 학습 데이터로더 (YOLOv8는 내부적으로 사용하지 않지만 인터페이스 통일)\n",
        "            val_loader: 검증 데이터로더\n",
        "            test_loader: 테스트 데이터로더\n",
        "            epochs: 학습 에포크 수\n",
        "            imgsz: 입력 이미지 크기\n",
        "            batch_size: 배치 크기\n",
        "            lr: 학습률 (YOLOv8는 내부적으로 관리)\n",
        "            patience: Early stopping patience (과적합 방지)\n",
        "        \"\"\"\n",
        "        OpLog(f\"YOLOv8{self.model_size} 모델 학습 시작\", bLines=True)\n",
        "\n",
        "        # YAML 파일과 labels를 항상 새로 생성\n",
        "        OpLog(\"YAML 파일 및 레이블 재생성 중...\", bLines=True)\n",
        "        self.preJob(annotation_dir, image_dir, yaml_file, yaml_label_dir)\n",
        "\n",
        "        # YOLOv8 학습 시작 (YOLOv8는 내부적으로 전체 에포크를 학습하고 검증까지 자동 수행)\n",
        "        data_root = os.path.dirname(image_dir)\n",
        "        results = self.model.train(\n",
        "            data=yaml_file,\n",
        "            epochs=epochs,\n",
        "            imgsz=imgsz,\n",
        "            batch=batch_size,\n",
        "            device=DEVICE_TYPE,\n",
        "            project=os.path.join(data_root, \"yolo_results\"),\n",
        "            name=f\"yolov8{self.model_size}_train\",\n",
        "            exist_ok=True,\n",
        "            patience=patience,  # Early stopping (과적합시 훈련 종료)\n",
        "            save=True,\n",
        "            plots=True,\n",
        "        )\n",
        "        OpLog(f\"YOLOv8 학습 완료!\", bLines=True)\n",
        "\n",
        "        # YOLOv8 best/last 모델 파일 복사\n",
        "        try:\n",
        "            results_dir = os.path.join(data_root, \"yolo_results\", f\"yolov8{self.model_size}_train\")\n",
        "            weights_dir = os.path.join(results_dir, \"weights\")\n",
        "            best_pt = os.path.join(weights_dir, \"best.pt\")\n",
        "            last_pt = os.path.join(weights_dir, \"last.pt\")\n",
        "\n",
        "            makedirs(MODEL_FILES)\n",
        "            if os.path.exists(best_pt):\n",
        "                shutil.copy(best_pt, os.path.join(MODEL_FILES, \"yolobest.pt\"))\n",
        "                OpLog(f\"YOLOv8 best 모델 복사 완료: yolobest.pt\", bLines=False)\n",
        "\n",
        "            if os.path.exists(last_pt):\n",
        "                shutil.copy(last_pt, os.path.join(MODEL_FILES, \"yololast.pt\"))\n",
        "                OpLog(f\"YOLOv8 last 모델 복사 완료: yololast.pt\", bLines=False)\n",
        "        except Exception as e:\n",
        "            OpLog(f\"YOLOv8 모델 파일 복사 중 오류: {e}\", bLines=False)\n",
        "\n",
        "        # YOLOv8 학습 결과에서 각 에폭의 메트릭을 CSV에 저장\n",
        "        try:\n",
        "            # YOLOv8 results.csv 파일에서 메트릭 읽기\n",
        "            results_dir = os.path.join(data_root, \"yolo_results\", f\"yolov8{self.model_size}_train\")\n",
        "            results_csv = os.path.join(results_dir, \"results.csv\")\n",
        "\n",
        "            if os.path.exists(results_csv):\n",
        "                import pandas as pd\n",
        "                yolo_results = pd.read_csv(results_csv)\n",
        "\n",
        "                # 각 에폭의 메트릭을 RESULT_CSV에 저장\n",
        "                for idx, row in yolo_results.iterrows():\n",
        "                    epoch_num = idx + 1\n",
        "\n",
        "                    # YOLOv8 결과에서 메트릭 추출 (컬럼명은 YOLOv8 버전에 따라 다를 수 있음)\n",
        "                    train_loss = row.get('train/box_loss', 0) + row.get('train/cls_loss', 0) + row.get('train/dfl_loss', 0)\n",
        "                    val_loss = row.get('val/box_loss', 0) + row.get('val/cls_loss', 0) + row.get('val/dfl_loss', 0)\n",
        "                    mAP50 = row.get('metrics/mAP50(B)', None)\n",
        "                    mAP50_95 = row.get('metrics/mAP50-95(B)', None)\n",
        "                    precision = row.get('metrics/precision(B)', None)\n",
        "                    recall = row.get('metrics/recall(B)', None)\n",
        "\n",
        "                    # 학습 메트릭 저장\n",
        "                    self.save_metrics_to_csv(\n",
        "                        model_name=self.getMyName(),\n",
        "                        epoch_index=epoch_num,\n",
        "                        max_epochs=epochs,\n",
        "                        train_loss=train_loss if train_loss > 0 else None,\n",
        "                        current_lr=lr,\n",
        "                        val_loss=val_loss if val_loss > 0 else None,\n",
        "                        mAP50=mAP50,\n",
        "                        mAP50_95=mAP50_95,\n",
        "                        precision=precision,\n",
        "                        recall=recall,\n",
        "                        mode=\"train\",\n",
        "                    )\n",
        "\n",
        "                OpLog(f\"YOLOv8 학습 메트릭 {len(yolo_results)}개 에폭 저장 완료\", bLines=False)\n",
        "        except Exception as e:\n",
        "            OpLog(f\"YOLOv8 결과 파싱 중 오류: {e}\", bLines=False)\n",
        "\n",
        "        # 학습 완료 후 최종 검증 및 테스트 (1회만 수행)\n",
        "        if val_loader is not None:\n",
        "            OpLog(\"최종 검증 수행 중...\", bLines=True)\n",
        "            self.evalModel(yaml_file, val_loader, epochs, epochs)\n",
        "        if test_loader is not None:\n",
        "            OpLog(\"최종 테스트 수행 중...\", bLines=True)\n",
        "            self.testModel(test_img_dir, test_loader, epochs, epochs)\n",
        "\n",
        "        # 학습 결과 시각화\n",
        "        self.plot_results()\n",
        "        return results\n",
        "    def evalModel(self, yaml_file, val_loader, epoch, max_epochs):\n",
        "        \"\"\"\n",
        "        검증 데이터셋에 대한 모델 평가 (BaseModel 인터페이스 구현)\n",
        "        Args:\n",
        "            yaml_file: YAML 파일 경로\n",
        "            val_loader: 검증 데이터로더\n",
        "            epoch: 현재 에포크 번호\n",
        "            max_epochs: 전체 에포크 수\n",
        "        \"\"\"\n",
        "        OpLog(f\"[Epoch {epoch}/{max_epochs}] Validation 시작\", bLines=True)\n",
        "\n",
        "        # 모델 검증\n",
        "        metrics = self.model.val(\n",
        "            data=yaml_file,\n",
        "            device=DEVICE_TYPE,\n",
        "            split=\"val\",\n",
        "            plots=False,  # 매 에포크마다 플롯 생성 방지\n",
        "        )\n",
        "\n",
        "        # 주요 메트릭 추출\n",
        "        mAP50 = float(metrics.box.map50)\n",
        "        mAP50_95 = float(metrics.box.map)\n",
        "        precision = float(metrics.box.mp)\n",
        "        recall = float(metrics.box.mr)\n",
        "        val_loss = 1.0 - mAP50_95  # mAP를 손실로 변환 (높을수록 좋으므로 1에서 빼기)\n",
        "\n",
        "        # 검증 손실 저장\n",
        "        self.val_losses.append(val_loss)\n",
        "        OpLog(\n",
        "            f\"mAP50: {mAP50:.4f}, mAP50-95: {mAP50_95:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\",\n",
        "            bLines=False,\n",
        "        )\n",
        "\n",
        "        # 메트릭 딕셔너리 생성\n",
        "        metrics_dict = {\n",
        "            \"mAP50\": mAP50,\n",
        "            \"mAP50_95\": mAP50_95,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "        }\n",
        "\n",
        "        # 공통 헬퍼로 저장 및 시각화\n",
        "        self._save_eval_metrics(\n",
        "            epoch=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            metrics_dict=metrics_dict,\n",
        "            train_loss=0.0,\n",
        "            val_loss=val_loss,\n",
        "            current_lr=0.0,\n",
        "        )\n",
        "        return val_loss\n",
        "    def testModel(self, test_img_dir, test_loader, epoch, max_epochs):\n",
        "        \"\"\"\n",
        "        테스트 데이터셋에 대한 모델 평가 (BaseModel 인터페이스 구현)\n",
        "        Args:\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            test_loader: 테스트 데이터로더\n",
        "            epoch: 현재 에포크 번호\n",
        "            max_epochs: 전체 에포크 수\n",
        "        \"\"\"\n",
        "        OpLog(f\"[Epoch {epoch}/{max_epochs}] Test 시작\", bLines=True)\n",
        "\n",
        "        # 테스트 이미지에 대한 예측 수행\n",
        "        results = self.model.predict(\n",
        "            source=test_img_dir,\n",
        "            conf=0.25,\n",
        "            save=False,\n",
        "            device=DEVICE_TYPE,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        # 예측 결과 수집\n",
        "        predictions = []\n",
        "        for result in results:\n",
        "            pred_dict = {\n",
        "                \"boxes\": result.boxes.xyxy.cpu().numpy() if result.boxes else [],\n",
        "                \"scores\": result.boxes.conf.cpu().numpy() if result.boxes else [],\n",
        "                \"labels\": result.boxes.cls.cpu().numpy() if result.boxes else [],\n",
        "                \"filename\": os.path.basename(result.path),\n",
        "            }\n",
        "            predictions.append(pred_dict)\n",
        "        OpLog(f\"테스트 이미지 {len(predictions)}개 예측 완료\", bLines=False)\n",
        "\n",
        "        # 공통 헬퍼로 통계 계산, 저장 및 시각화\n",
        "        self._save_test_metrics(\n",
        "            epoch=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            predictions=predictions,\n",
        "            test_img_dir=test_img_dir,\n",
        "            train_loss=0.0,\n",
        "            current_lr=0.0,\n",
        "        )\n",
        "\n",
        "        # test_loss 계산 후 반환\n",
        "        total_detections = sum(len(p[\"boxes\"]) for p in predictions)\n",
        "        avg_conf = sum(\n",
        "            p[\"scores\"].mean() if len(p[\"scores\"]) > 0 else 0.0 for p in predictions\n",
        "        ) / max(len(predictions), 1)\n",
        "        test_loss = 1.0 - avg_conf\n",
        "\n",
        "        # Submission 파일 생성 (매 테스트마다 수행)\n",
        "        # 클래스 이름 가져오기 - yaml_file은 test_img_dir의 부모의 하위 디렉토리에 있음\n",
        "        # test_img_dir = data/oraldrug/test_images\n",
        "        # data_dir = data/oraldrug/1.drug_Image_annotation_allOK (또는 유사)\n",
        "        # yaml_file = data_dir/yolo_yaml.yaml\n",
        "\n",
        "        parent_dir = os.path.dirname(test_img_dir)  # data/oraldrug\n",
        "        yaml_file = None\n",
        "\n",
        "        # 부모 디렉토리의 하위 디렉토리에서 yolo_yaml.yaml 찾기\n",
        "        for item in os.listdir(parent_dir):\n",
        "            item_path = os.path.join(parent_dir, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                yaml_candidate = os.path.join(item_path, \"yolo_yaml.yaml\")\n",
        "                if os.path.exists(yaml_candidate):\n",
        "                    yaml_file = yaml_candidate\n",
        "                    break\n",
        "\n",
        "        if yaml_file and os.path.exists(yaml_file):\n",
        "            import yaml\n",
        "            with open(yaml_file, 'r', encoding='utf-8') as f:\n",
        "                yaml_data = yaml.safe_load(f)\n",
        "                class_names = yaml_data.get('names', [])\n",
        "            OpLog(f\"YAML 파일 로드: {yaml_file}\", bLines=False)\n",
        "        else:\n",
        "            OpLog(f\"Warning: yolo_yaml.yaml을 찾을 수 없습니다. 기본 클래스 이름 사용\", bLines=False)\n",
        "            class_names = list(range(self.num_classes)) if self.num_classes else []\n",
        "\n",
        "        self.CreateSubmission(\n",
        "            predictions=predictions,\n",
        "            test_img_dir=test_img_dir,\n",
        "            class_names=class_names,\n",
        "            save_image_num=10\n",
        "        )\n",
        "\n",
        "        return test_loss\n",
        "    def predict(self, source, conf=0.25, save=True):\n",
        "        \"\"\"\n",
        "        이미지에 대한 예측 수행\n",
        "        Args:\n",
        "            source: 이미지 경로, 폴더 경로, 또는 이미지 URL\n",
        "            conf: 신뢰도 임계값\n",
        "            save: 결과 저장 여부\n",
        "        \"\"\"\n",
        "        results = self.model.predict(\n",
        "            source=source,\n",
        "            conf=conf,\n",
        "            save=save,\n",
        "            project=os.path.join(BASE_DIR, \"yolo_results\"),\n",
        "            name=f\"yolov8{self.model_size}_predict\",\n",
        "            exist_ok=True,\n",
        "        )\n",
        "        return results\n",
        "    def load_yolo_model(self, model_path):\n",
        "        \"\"\"YOLOv8 모델 로드\"\"\"\n",
        "        if not os.path.exists(model_path):\n",
        "            OpLog(f\"모델 파일을 찾을 수 없습니다: {model_path}\", bLines=True)\n",
        "            return False\n",
        "        self.model = YOLO(model_path)\n",
        "        OpLog(f\"YOLOv8 모델 로드 완료: {model_path}\", bLines=True)\n",
        "        return True\n",
        "    def save_yolo_model(self, save_path=None):\n",
        "        \"\"\"YOLOv8 모델 저장\"\"\"\n",
        "        if save_path is None:\n",
        "            save_path = os.path.join(MODEL_FILES, f\"yolov8{self.model_size}_final.pt\")\n",
        "        makedirs(os.path.dirname(save_path))\n",
        "\n",
        "        # YOLOv8 모델 내보내기\n",
        "        self.model.export(format=\"torchscript\", dynamic=False)\n",
        "        OpLog(f\"YOLOv8 모델 저장됨: {save_path}\", bLines=True)\n",
        "        return save_path\n",
        "    def TestModelByBest(self, pt_file, test_img_dir, test_loader=None):\n",
        "        \"\"\"Best 모델 파일로 테스트 및 Submission 생성\n",
        "\n",
        "        Args:\n",
        "            pt_file: 로드할 .pt 모델 파일 경로\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            test_loader: 테스트 데이터 로더 (선택, 사용하지 않음)\n",
        "        \"\"\"\n",
        "        OpLog(f\"Best 모델로 테스트 시작: {pt_file}\", bLines=True)\n",
        "\n",
        "        # 모델 로드\n",
        "        if not self.load_yolo_model(pt_file):\n",
        "            OpLog(f\"모델 로드 실패: {pt_file}\", bLines=True)\n",
        "            return False\n",
        "\n",
        "        # testModel 호출 (epoch=1, max_epochs=1로 설정)\n",
        "        self.testModel(test_img_dir, test_loader, epoch=1, max_epochs=1)\n",
        "\n",
        "        OpLog(f\"Best 모델 테스트 및 Submission 생성 완료\", bLines=True)\n",
        "        return True\n",
        "    def plot_results(self):\n",
        "        \"\"\"학습 결과 시각화\"\"\"\n",
        "        results_dir = os.path.join(\n",
        "            BASE_DIR, \"yolo_results\", f\"yolov8{self.model_size}_train\"\n",
        "        )\n",
        "        results_file = os.path.join(results_dir, \"results.png\")\n",
        "        if os.path.exists(results_file):\n",
        "            OpLog(f\"학습 결과 그래프: {results_file}\", bLines=False)\n",
        "        else:\n",
        "            OpLog(\"학습 결과 파일을 찾을 수 없습니다.\", bLines=False)\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0lZAte3A4xl"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 06. Faster R-CNN 모델 정의<br>\n",
        "════════════════════════════════════════"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G_n4pM4gA4xl"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Pu19GEfYA4xl"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "class FasterRCNNModel(BaseModel):\n",
        "    def save_model(self, epoch_index, is_best=False, **kwargs):\n",
        "        \"\"\"현재 모델 상태를 저장 (FasterRCNN 전용 파일명)\n",
        "        Args:\n",
        "            epoch_index: 현재 에포크 번호\n",
        "            is_best: Best 모델인지 여부\n",
        "            **kwargs: 추가로 저장할 데이터 (model_state_dict, train_losses 등)\n",
        "        \"\"\"\n",
        "        save_dir = MODEL_FILES\n",
        "        makedirs(save_dir)\n",
        "\n",
        "        # FasterRCNN 전용 파일명\n",
        "        if is_best:\n",
        "            filename = os.path.join(save_dir, \"fasterbest.pt\")\n",
        "        else:\n",
        "            filename = os.path.join(save_dir, \"fasterlast.pt\")\n",
        "\n",
        "        # 기본 저장 데이터\n",
        "        checkpoint = {\n",
        "            \"epoch\": epoch_index,\n",
        "            \"is_best\": is_best,\n",
        "            \"model_name\": self.getMyName(),\n",
        "        }\n",
        "\n",
        "        # kwargs로 전달된 추가 데이터 저장\n",
        "        checkpoint.update(kwargs)\n",
        "        torch.save(checkpoint, filename)\n",
        "        if is_best:\n",
        "            print(f\"  Best 모델 저장됨: {filename}\")\n",
        "            OpLog(f\"Best model saved: {filename}\")\n",
        "        else:\n",
        "            OpLog(f\"모델 저장됨: {filename}\", bLines=False)\n",
        "    \"\"\"\n",
        "    Faster R-CNN 기반 객체 탐지 모델\n",
        "    - torchvision의 사전 학습된 Faster R-CNN 사용\n",
        "    - ResNet50-FPN 백본 활용\n",
        "    - 객체 탐지 및 분류 동시 수행\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, backbone=\"resnet50\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: 클래스 수 (필수, +1은 배경 클래스)\n",
        "            backbone: 백본 네트워크 ('resnet50', 'mobilenet' 등)\n",
        "        \"\"\"\n",
        "        super().__init__() # Changed from super(FasterRCNNModel, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.num_classes = num_classes + 1  # +1 for background\n",
        "\n",
        "        # 사전 훈련된 Faster R-CNN 모델 로드\n",
        "        if backbone == \"resnet50\":\n",
        "            self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
        "                pretrained=True\n",
        "            )\n",
        "        elif backbone == \"mobilenet\":\n",
        "            self.model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(\n",
        "                pretrained=True\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
        "\n",
        "        # 분류 헤드를 클래스 수에 맞게 변경\n",
        "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "        self.model.roi_heads.box_predictor = (\n",
        "            torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
        "                in_features, self.num_classes\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 학습 이력 저장용\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_loss = float(\"inf\")\n",
        "        OpLog(\n",
        "            f\"Faster R-CNN 모델 초기화 완료 (backbone: {backbone}, classes: {self.num_classes})\",\n",
        "            bLines=False,\n",
        "        )\n",
        "    def getMyName(self):\n",
        "        return f\"FasterRCNNModel_{self.backbone}\"\n",
        "    def getOptimizer(self, lr=0.001, gubun=\"freeze\"):\n",
        "        \"\"\"\n",
        "        Faster R-CNN 모델의 optimizer를 반환\n",
        "        Args:\n",
        "            lr: 학습률\n",
        "            gubun: 최적화 방식\n",
        "                - 'freeze': backbone을 고정하고 head만 학습\n",
        "                - 'partial': backbone은 낮은 lr, head는 일반 lr로 학습\n",
        "                - 'all': 전체 모델 학습\n",
        "        Returns:\n",
        "            optimizer: torch.optim.SGD optimizer\n",
        "        \"\"\"\n",
        "        if gubun == \"partial\":\n",
        "            # Backbone과 head를 다른 학습률로 설정\n",
        "            params = [\n",
        "                {\n",
        "                    \"params\": self.model.backbone.parameters(),\n",
        "                    \"lr\": lr * 0.1,\n",
        "                },  # backbone은 10% lr\n",
        "                {\n",
        "                    \"params\": self.model.roi_heads.parameters(),\n",
        "                    \"lr\": lr,\n",
        "                },  # head는 100% lr\n",
        "            ]\n",
        "            OpLog(\n",
        "                f\"Optimizer 생성: partial mode (backbone_lr={lr*0.1:.6f}, head_lr={lr:.6f})\",\n",
        "                bLines=False,\n",
        "            )\n",
        "        elif gubun == \"freeze\":\n",
        "            # Backbone을 고정하고 head만 학습\n",
        "            for param in self.model.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "            params = self.model.roi_heads.parameters()\n",
        "            OpLog(f\"Optimizer 생성: freeze mode (only head, lr={lr:.6f})\", bLines=False)\n",
        "        else:  # 'all' or default\n",
        "            # 전체 모델 학습\n",
        "            params = self.model.parameters()\n",
        "            OpLog(f\"Optimizer 생성: all mode (lr={lr:.6f})\", bLines=False)\n",
        "        optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "        return optimizer\n",
        "    def fit(\n",
        "        self,\n",
        "        test_img_dir,\n",
        "        gubun=\"freeze\",\n",
        "        train_loader=None,\n",
        "        val_loader=None,\n",
        "        test_loader=None,\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch_size=16,\n",
        "        lr=0.005,\n",
        "        patience=10,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Faster R-CNN 모델 학습 (BaseModel 인터페이스 준수)\n",
        "        Args:\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            gubun: 최적화 방식 ('freeze', 'partial', 'all')\n",
        "            train_loader: 학습 데이터 로더\n",
        "            val_loader: 검증 데이터 로더 (선택)\n",
        "            test_loader: 테스트 데이터 로더 (선택)\n",
        "            epochs: 학습 에포크 수\n",
        "            imgsz: 입력 이미지 크기 (FasterRCNN은 사용하지 않음, 인터페이스 통일용)\n",
        "            batch_size: 배치 크기 (FasterRCNN은 사용하지 않음, 인터페이스 통일용)\n",
        "            lr: 학습률\n",
        "            patience: Early stopping patience (과적합 방지)\n",
        "        \"\"\"\n",
        "        OpLog(f\"Faster R-CNN 모델 학습 시작 (Epochs: {epochs}, LR: {lr}, Patience: {patience})\", bLines=True)\n",
        "        self.model.to(DEVICE_TYPE)\n",
        "\n",
        "        # 옵티마이저 및 스케줄러 설정\n",
        "        params = [p for p in self.model.parameters() if p.requires_grad]\n",
        "        self.optimizer = self.getOptimizer(lr=lr, gubun=\"partial\")\n",
        "        self.lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            self.optimizer, step_size=3, gamma=0.1\n",
        "        )\n",
        "\n",
        "        # Early stopping 변수 초기화\n",
        "        patience_counter = 0\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        # 학습 루프\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0.0\n",
        "            batch_count = 0\n",
        "            for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "                # 이미지를 디바이스로 이동\n",
        "                images = [img.to(DEVICE_TYPE) for img in images]\n",
        "                # 타겟 준비\n",
        "                if isinstance(targets, torch.Tensor):\n",
        "                    targets = [\n",
        "                        {\n",
        "                            \"boxes\": torch.tensor(\n",
        "                                [[0, 0, 224, 224]], dtype=torch.float32\n",
        "                            ).to(DEVICE_TYPE),\n",
        "                            \"labels\": torch.tensor(\n",
        "                                [label.item()], dtype=torch.int64\n",
        "                            ).to(DEVICE_TYPE),\n",
        "                        }\n",
        "                        for label in targets\n",
        "                    ]\n",
        "                else:\n",
        "                    targets = [\n",
        "                        {k: v.to(DEVICE_TYPE) for k, v in t.items()} for t in targets\n",
        "                    ]\n",
        "                # Forward pass\n",
        "                loss_dict = self.model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                # Backward pass\n",
        "                self.optimizer.zero_grad()\n",
        "                losses.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += losses.item()\n",
        "                batch_count += 1\n",
        "                msg =  f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {losses.item():.4f}\"\n",
        "                print(msg,end=\"\\r\")\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    OpLog(\n",
        "                        f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {losses.item():.4f}\",\n",
        "                        bLines=False,\n",
        "                    )\n",
        "\n",
        "            # 에포크 평균 손실\n",
        "            avg_train_loss = epoch_loss / batch_count\n",
        "            self.train_losses.append(avg_train_loss)\n",
        "\n",
        "            # 현재 학습률 가져오기\n",
        "            current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "            # 매 epoch마다 학습 메트릭 저장\n",
        "            self.save_metrics_to_csv(\n",
        "                model_name=self.getMyName(),\n",
        "                epoch_index=epoch + 1,\n",
        "                max_epochs=epochs,\n",
        "                train_loss=avg_train_loss,\n",
        "                current_lr=current_lr,\n",
        "                mode=\"train\",\n",
        "            )\n",
        "\n",
        "            # 매 epoch 검증\n",
        "            if val_loader is not None:\n",
        "                self.evalModel(val_loader, epoch + 1, epochs)\n",
        "                # Best 모델 저장 및 early stopping 검사\n",
        "                current_val_loss = self.val_losses[-1]\n",
        "                if current_val_loss < best_val_loss:\n",
        "                    best_val_loss = current_val_loss\n",
        "                    self.best_val_loss = best_val_loss\n",
        "                    patience_counter = 0\n",
        "                    OpLog(f\"Best 모델 업데이트! Val Loss: {best_val_loss:.4f}\", bLines=False)\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    OpLog(f\"Patience counter: {patience_counter}/{patience}\", bLines=False)\n",
        "\n",
        "                    if patience_counter >= patience:\n",
        "                        OpLog(f\"Early stopping triggered! {patience} epochs without improvement\", bLines=True)\n",
        "                        break\n",
        "                    self.save_model(\n",
        "                        epoch_index=epoch + 1,\n",
        "                        is_best=True,\n",
        "                        model_state_dict=self.model.state_dict(),\n",
        "                        optimizer_state_dict=self.optimizer.state_dict(),\n",
        "                        train_loss=avg_train_loss,\n",
        "                        val_loss=self.val_losses[-1],\n",
        "                    )\n",
        "\n",
        "            # 10 epoch마다 테스트\n",
        "            if test_loader is not None and (epoch + 1) % 10 == 0:\n",
        "                self.testModel(test_img_dir, test_loader, epoch + 1, epochs)\n",
        "\n",
        "            # 매 epoch마다 모델 저장\n",
        "            self.save_model(\n",
        "                epoch_index=epoch + 1,\n",
        "                is_best=False,\n",
        "                model_state_dict=self.model.state_dict(),\n",
        "                optimizer_state_dict=self.optimizer.state_dict(),\n",
        "                train_loss=avg_train_loss,\n",
        "                val_loss=self.val_losses[-1] if val_loader else None,\n",
        "                test_loss=(\n",
        "                    self.test_losses[-1]\n",
        "                    if (test_loader and len(self.test_losses) > 0)\n",
        "                    else None\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            # 학습률 스케줄러 업데이트\n",
        "            self.lr_scheduler.step()\n",
        "\n",
        "        # 학습 완료 후 최종 테스트 (early stopping으로 중간에 종료되었을 수도 있으므로)\n",
        "        if test_loader is not None:\n",
        "            OpLog(\"최종 테스트 수행 중...\", bLines=True)\n",
        "            final_epoch = epoch + 1  # 실제 학습이 완료된 에포크\n",
        "            self.testModel(test_img_dir, test_loader, final_epoch, epochs)\n",
        "        OpLog(\"Faster R-CNN 학습 완료!\", bLines=True)\n",
        "        self.plot_results()\n",
        "    def evalModel(self, val_loader, epoch, max_epochs):\n",
        "        \"\"\"검증 모드\"\"\"\n",
        "        self.model.train()  # Faster R-CNN은 train 모드에서 loss 반환\n",
        "        val_loss = 0.0\n",
        "        batch_count = 0\n",
        "        predictions_all = []\n",
        "        with torch.no_grad():\n",
        "            for images, targets in val_loader:\n",
        "                images = [img.to(DEVICE_TYPE) for img in images]\n",
        "                # 타겟 준비\n",
        "                if isinstance(targets, torch.Tensor):\n",
        "                    targets = [\n",
        "                        {\n",
        "                            \"boxes\": torch.tensor(\n",
        "                                [[0, 0, 224, 224]], dtype=torch.float32\n",
        "                            ).to(DEVICE_TYPE),\n",
        "                            \"labels\": torch.tensor(\n",
        "                                [label.item()], dtype=torch.int64\n",
        "                            ).to(DEVICE_TYPE),\n",
        "                        }\n",
        "                        for label in targets\n",
        "                    ]\n",
        "                else:\n",
        "                    targets = [\n",
        "                        {k: v.to(DEVICE_TYPE) for k, v in t.items()} for t in targets\n",
        "                    ]\n",
        "                loss_dict = self.model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                val_loss += losses.item()\n",
        "                batch_count += 1\n",
        "                # 예측 수집 (시각화용)\n",
        "                self.model.eval()\n",
        "                preds = self.model(images)\n",
        "                predictions_all.extend(preds)\n",
        "                self.model.train()\n",
        "        avg_val_loss = val_loss / batch_count if batch_count > 0 else 0.0\n",
        "        self.val_losses.append(avg_val_loss)\n",
        "\n",
        "        # 예측 통계 계산\n",
        "        total_detections = sum(len(p[\"boxes\"]) for p in predictions_all)\n",
        "        avg_confidence = sum(\n",
        "            p[\"scores\"].mean().item() if len(p[\"scores\"]) > 0 else 0.0\n",
        "            for p in predictions_all\n",
        "        ) / max(len(predictions_all), 1)\n",
        "\n",
        "        # 정밀도/재현율 근사 계산 (신뢰도 기반)\n",
        "        precision = avg_confidence if avg_confidence > 0 else None\n",
        "        recall = avg_confidence * 0.9 if avg_confidence > 0 else None  # 근사값\n",
        "        OpLog(\n",
        "            f\"Epoch [{epoch}/{max_epochs}] - Val Loss: {avg_val_loss:.4f}, Detections: {total_detections}, Avg Conf: {avg_confidence:.4f}\", bLines=True\n",
        "        )\n",
        "\n",
        "        # 메트릭 딕셔너리 생성\n",
        "        current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
        "        metrics_dict = {\n",
        "            'mAP50': None,  # FasterRCNN은 mAP 계산 안 함\n",
        "            'mAP50_95': None,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'total_detections': total_detections,\n",
        "            'avg_confidence': avg_confidence,\n",
        "        }\n",
        "\n",
        "        # 공통 헬퍼로 저장 및 시각화\n",
        "        self._save_eval_metrics(\n",
        "            epoch=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            metrics_dict=metrics_dict,\n",
        "            train_loss=self.train_losses[-1] if len(self.train_losses) > 0 else None,\n",
        "            val_loss=avg_val_loss,\n",
        "            current_lr=current_lr,\n",
        "        )\n",
        "    def testModel(self, test_img_dir, test_loader, epoch, max_epochs):\n",
        "        \"\"\"테스트 모드\n",
        "\n",
        "        Args:\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            test_loader: 테스트 데이터 로더 (사용하지 않음, 인터페이스 통일용)\n",
        "            epoch: 현재 에포크\n",
        "            max_epochs: 최대 에포크\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        predictions_all = []\n",
        "\n",
        "        # test_img_dir에서 직접 이미지 파일 리스트 가져오기\n",
        "        if not os.path.exists(test_img_dir):\n",
        "            OpLog(f\"테스트 이미지 디렉토리가 없습니다: {test_img_dir}\", bLines=True)\n",
        "            return\n",
        "\n",
        "        image_files = [\n",
        "            f for f in os.listdir(test_img_dir)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))\n",
        "        ]\n",
        "\n",
        "        if len(image_files) == 0:\n",
        "            OpLog(f\"테스트 이미지가 없습니다: {test_img_dir}\", bLines=True)\n",
        "            return\n",
        "\n",
        "        # 전처리 변환 (FasterRCNN 표준)\n",
        "        from torchvision import transforms\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        with torch.no_grad():\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(test_img_dir, img_file)\n",
        "\n",
        "                # 이미지 로드 및 전처리\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                img_tensor = transform(img).to(DEVICE_TYPE)\n",
        "\n",
        "                # 예측 (배치 형태로 전달)\n",
        "                preds = self.model([img_tensor])\n",
        "\n",
        "                # 예측 결과에 파일명 추가\n",
        "                pred_dict = {\n",
        "                    \"boxes\": preds[0][\"boxes\"].cpu().numpy(),\n",
        "                    \"scores\": preds[0][\"scores\"].cpu().numpy(),\n",
        "                    \"labels\": preds[0][\"labels\"].cpu().numpy(),\n",
        "                    \"filename\": img_file,\n",
        "                }\n",
        "                predictions_all.append(pred_dict)\n",
        "\n",
        "        # 공통 헬퍼로 통계 계산, 저장 및 시각화\n",
        "        current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
        "        self._save_test_metrics(\n",
        "            epoch=epoch,\n",
        "            max_epochs=max_epochs,\n",
        "            predictions=predictions_all,\n",
        "            test_img_dir=test_img_dir,\n",
        "            train_loss=self.train_losses[-1] if len(self.train_losses) > 0 else None,\n",
        "            current_lr=current_lr,\n",
        "        )\n",
        "\n",
        "        # Submission 파일 생성 (최종 에포크일 때만)\n",
        "        # 클래스 이름 가져오기 (0-based index이므로 num_classes-1개)\n",
        "        class_names = list(range(self.num_classes - 1))  # -1은 배경 클래스 제외\n",
        "        self.CreateSubmission(\n",
        "            predictions=predictions_all,\n",
        "            test_img_dir=test_img_dir,\n",
        "            class_names=class_names,\n",
        "            save_image_num=10\n",
        "        )\n",
        "    def TestModelByBest(self, pt_file, test_img_dir, test_loader=None):\n",
        "        \"\"\"Best 모델 파일로 테스트 및 Submission 생성\n",
        "\n",
        "        Args:\n",
        "            pt_file: 로드할 .pt 모델 파일 경로\n",
        "            test_img_dir: 테스트 이미지 디렉토리\n",
        "            test_loader: 테스트 데이터 로더 (선택, 사용하지 않음)\n",
        "        \"\"\"\n",
        "        OpLog(f\"Best 모델로 테스트 시작: {pt_file}\", bLines=True)\n",
        "\n",
        "        # 모델 로드\n",
        "        checkpoint = self.load_model(pt_file)\n",
        "        if checkpoint is None:\n",
        "            OpLog(f\"모델 로드 실패: {pt_file}\", bLines=True)\n",
        "            return False\n",
        "\n",
        "        # 모델 state_dict 로드\n",
        "        if 'model_state_dict' in checkpoint:\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.model.to(DEVICE_TYPE)\n",
        "            OpLog(f\"FasterRCNN 모델 로드 완료: {pt_file}\", bLines=False)\n",
        "        else:\n",
        "            OpLog(f\"model_state_dict를 찾을 수 없습니다: {pt_file}\", bLines=True)\n",
        "            return False\n",
        "\n",
        "        # testModel 호출 (epoch=1, max_epochs=1로 설정)\n",
        "        self.testModel(test_img_dir, test_loader, epoch=1, max_epochs=1)\n",
        "\n",
        "        OpLog(f\"Best 모델 테스트 및 Submission 생성 완료\", bLines=True)\n",
        "        return True\n",
        "    def plot_results(self):\n",
        "        \"\"\"학습 결과 시각화\"\"\"\n",
        "        if len(self.train_losses) == 0:\n",
        "            OpLog(\"학습 이력이 없습니다.\", bLines=False)\n",
        "            return\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # 손실 그래프\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_losses, label=\"Train Loss\", marker=\"o\")\n",
        "        if len(self.val_losses) > 0:\n",
        "            plt.plot(self.val_losses, label=\"Val Loss\", marker=\"s\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Faster R-CNN Training/Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # 손실 통계\n",
        "        plt.subplot(1, 2, 2)\n",
        "        stats_text = f\"Training Statistics\\n\\n\"\n",
        "        stats_text += f\"Epochs: {len(self.train_losses)}\\n\"\n",
        "        stats_text += f\"Final Train Loss: {self.train_losses[-1]:.4f}\\n\"\n",
        "        if len(self.val_losses) > 0:\n",
        "            stats_text += f\"Final Val Loss: {self.val_losses[-1]:.4f}\\n\"\n",
        "            stats_text += f\"Best Val Loss: {self.best_val_loss:.4f}\\n\"\n",
        "        plt.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment=\"center\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # 그래프 저장\n",
        "        save_dir = os.path.join(BASE_DIR, \"oraldrug\", \"results\")\n",
        "        makedirs(save_dir)\n",
        "        save_path = os.path.join(save_dir, \"fasterrcnn_training_results.png\")\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "        OpLog(f\"학습 결과 그래프 저장: {save_path}\", bLines=False)\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqItxhroA4xm"
      },
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 07. 모델 생성 및 학습 실행<br>\n",
        "════════════════════════════════════════"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4gMBKL-cA4xm"
      },
      "outputs": [],
      "source": [
        "def MakeModel(model_type, num_classes, model_size=\"n\", backbone=\"resnet50\", bBestLoad=False):\n",
        "    \"\"\"\n",
        "    모델 생성 함수\n",
        "    Args:\n",
        "        model_type: 모델 유형 (\"yolov8\" 또는 \"faster\")\n",
        "        num_classes: 클래스 수\n",
        "        model_size: YOLOv8 모델 크기 ('n', 's', 'm', 'l', 'x'), 기본값 'n'\n",
        "        backbone: FasterRCNN 백본 ('resnet50', 'mobilenet'), 기본값 'resnet50'\n",
        "        bBestLoad: True이면 best 모델 파일 로드 (yolobest.pt 또는 fasterbest.pt), 기본값 False\n",
        "    Returns:\n",
        "        model: 생성된 모델 객체\n",
        "    \"\"\"\n",
        "    if model_type == \"faster\":\n",
        "        OpLog(f\"FasterRCNN 모델 생성 중... (backbone={backbone}, num_classes={num_classes})\", bLines=False)\n",
        "        model = FasterRCNNModel(num_classes=num_classes, backbone=backbone)\n",
        "\n",
        "        # bBestLoad가 True이면 best 모델 로드\n",
        "        if bBestLoad:\n",
        "            best_model_path = os.path.join(MODEL_FILES, \"fasterbest.pt\")\n",
        "            if os.path.exists(best_model_path):\n",
        "                OpLog(f\"Best FasterRCNN 모델 로드 중: {best_model_path}\", bLines=True)\n",
        "                model.load_model(best_model_path)\n",
        "            else:\n",
        "                OpLog(f\"Best 모델 파일이 없습니다: {best_model_path}. 새로운 모델로 시작합니다.\", bLines=True)\n",
        "\n",
        "        return model\n",
        "    elif model_type == \"yolov8\":\n",
        "        OpLog(f\"YOLOv8 모델 생성 중... (model_size={model_size}, num_classes={num_classes})\", bLines=False)\n",
        "        model = YOLOv8Model(model_size=model_size, num_classes=num_classes)\n",
        "\n",
        "        # bBestLoad가 True이면 best 모델 로드\n",
        "        if bBestLoad:\n",
        "            best_model_path = os.path.join(MODEL_FILES, \"yolobest.pt\")\n",
        "            if os.path.exists(best_model_path):\n",
        "                OpLog(f\"Best YOLOv8 모델 로드 중: {best_model_path}\", bLines=True)\n",
        "                model.load_model(best_model_path)\n",
        "            else:\n",
        "                OpLog(f\"Best 모델 파일이 없습니다: {best_model_path}. 새로운 모델로 시작합니다.\", bLines=True)\n",
        "\n",
        "        return model\n",
        "    else:\n",
        "        raise ValueError(f\"지원되지 않는 모델 타입: {model_type}. 'yolov8' 또는 'faster'를 사용하세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SWZbg0p0A4xm"
      },
      "outputs": [],
      "source": [
        "def Execute_Train(model_type, data_dir, model_size=\"n\", backbone=\"resnet50\", epochs=50, batch_size=16, lr=0.001, bBestLoad=False, **kwargs):\n",
        "    \"\"\"\n",
        "    모델 생성 및 학습 실행 함수\n",
        "\n",
        "    Args:\n",
        "        model_type: 모델 유형 (\"yolov8\" 또는 \"faster\")\n",
        "        data_dir: 데이터 디렉토리 경로\n",
        "        model_size: YOLOv8 모델 크기 ('n', 's', 'm', 'l', 'x'), 기본값 'n'\n",
        "        backbone: FasterRCNN 백본 ('resnet50', 'mobilenet'), 기본값 'resnet50'\n",
        "        epochs: 학습 에포크 수, 기본값 50\n",
        "        batch_size: 배치 크기, 기본값 16\n",
        "        lr: 학습률, 기본값 0.001 (FasterRCNN은 자동으로 0.005 사용)\n",
        "        bBestLoad: True이면 best 모델 로드 (yolobest.pt/fasterbest.pt), 기본값 False\n",
        "        **kwargs: fit 메서드에 전달할 추가 파라미터\n",
        "            - imgsz: 이미지 크기 (기본값 640)\n",
        "            - patience: Early stopping patience (YOLOv8, 기본값 10)\n",
        "            - gubun: 최적화 방식 (FasterRCNN, 기본값 'partial')\n",
        "            - train_ratio: 학습/검증 분할 비율 (기본값 0.8)\n",
        "            - num_workers: 데이터 로더 워커 수 (기본값 2)\n",
        "            - transform_type: 데이터 증강 타입 (기본값 'A')\n",
        "    \"\"\"\n",
        "    # kwargs에서 공통 파라미터 추출\n",
        "    imgsz = kwargs.pop('imgsz', 640)\n",
        "    patience = kwargs.pop('patience', 10)\n",
        "    gubun = kwargs.pop('gubun', 'partial')\n",
        "    train_ratio = kwargs.pop('train_ratio', 0.8)\n",
        "    num_workers = kwargs.pop('num_workers', 2)\n",
        "    transform_type = kwargs.pop('transform_type', 'A')\n",
        "\n",
        "    # 경로 설정\n",
        "    image_dir, annotation_dir, yaml_file, yaml_label_dir, test_img_dir = GetConfig(data_dir)\n",
        "\n",
        "    # 클래스 수 계산\n",
        "    num_classes = count_classes(annotation_dir)\n",
        "    OpLog(f\"총 클래스 수: {num_classes}\", bLines=True)\n",
        "\n",
        "    # 모델 생성 (bBestLoad 전달)\n",
        "    model = MakeModel(model_type, num_classes=num_classes, model_size=model_size, backbone=backbone, bBestLoad=bBestLoad)\n",
        "\n",
        "    # 데이터 로더 생성\n",
        "    train_loader, val_loader, test_loader = GetLoaders(\n",
        "        annotation_dir, transform_type, image_dir, test_img_dir,\n",
        "        batch_size=batch_size, train_ratio=train_ratio, num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    # 모델 타입에 따라 fit 호출 방식 구분\n",
        "    if isinstance(model, YOLOv8Model):\n",
        "        # YOLOv8 모델 학습\n",
        "        model.fit(\n",
        "            annotation_dir=annotation_dir,\n",
        "            image_dir=image_dir,\n",
        "            yaml_file=yaml_file,\n",
        "            yaml_label_dir=yaml_label_dir,\n",
        "            test_img_dir=test_img_dir,\n",
        "            epochs=epochs,\n",
        "            imgsz=imgsz,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            test_loader=test_loader,\n",
        "            patience=patience,\n",
        "            **kwargs  # 추가 파라미터 전달\n",
        "        )\n",
        "    elif isinstance(model, FasterRCNNModel):\n",
        "        # Faster R-CNN 모델 학습\n",
        "        # FasterRCNN은 기본 lr이 더 높음\n",
        "        actual_lr = lr if lr > 0.001 else 0.005\n",
        "        model.fit(\n",
        "            test_img_dir,\n",
        "            gubun=gubun,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            test_loader=test_loader,\n",
        "            epochs=epochs,\n",
        "            imgsz=imgsz,\n",
        "            batch_size=batch_size,\n",
        "            lr=actual_lr,\n",
        "            **kwargs  # 추가 파라미터 전달\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"지원되지 않는 모델 타입: {type(model)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fq0iZsCmA4xz"
      },
      "outputs": [],
      "source": [
        "def testbest():\n",
        "    data_dir = r\"D:\\01.project\\EntryPrj\\data\\oraldrug\\1.drug_Image_annotation_allOK\"\n",
        "    image_dir, annotation_dir, yaml_file, yaml_label_dir, test_img_dir = GetConfig(data_dir)\n",
        "    # 클래스 수 계산\n",
        "    num_classes = count_classes(annotation_dir)\n",
        "    OpLog(f\"총 클래스 수: {num_classes}\", bLines=True)\n",
        "\n",
        "    # 모델 생성 (bBestLoad 전달)\n",
        "    model = MakeModel(\"yolov8\", 74)\n",
        "    model.TestModelByBest(MODEL_FILES + \"/yolobest.pt\", test_img_dir,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFtyaRgFA4xz"
      },
      "source": [
        "이 부분을 추가하여 직접 실행할 때만 testbest() 호출"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 07. Faster R-CNN 모델 생성<br>\n",
        "════════════════════════════════════════"
      ],
      "metadata": {
        "id": "fKr2wVS-Xr55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Corrected data_dir to point to Google Drive\n",
        "data_dir = '/content/drive/MyDrive/oraldrug/4.drug_Augmentation'\n",
        "\n",
        "#data_dir = r\"D:\\01.project\\EntryPrj\\data\\oraldrug\\1.drug_Image_annotation_allOK\"\n",
        "trans_type = [\"default\"]#, \"A\", \"B\"]\n",
        "for transform_type in trans_type:\n",
        "  Execute_Train(\n",
        "            model_type=\"faster\",           # 모델 타입: \"faster\" 또는 \"yolov8\"\n",
        "            data_dir=data_dir,              # 데이터 디렉토리 경로\n",
        "            backbone=\"resnet50\",            # FasterRCNN 백본: \"resnet50\" 또는 \"mobilenet\"\n",
        "            epochs=10,                      # 학습 에포크 수\n",
        "            batch_size=16,                  # 배치 크기\n",
        "            lr=0.005,                       # 학습률 (FasterRCNN 권장: 0.005)\n",
        "            bBestLoad=True,                # Best 모델 로드 여부 (fasterbest.pt)\n",
        "            imgsz=640,                      # 이미지 크기\n",
        "            patience=10,                    # Early stopping patience (에포크 수)\n",
        "            gubun=\"partial\",                # 최적화 방식: \"freeze\", \"partial\", \"all\"\n",
        "            train_ratio=0.8,                # 학습/검증 데이터 분할 비율\n",
        "            num_workers=4,                  # 데이터 로더 워커 수\n",
        "            transform_type=transform_type              # 데이터 증강 타입: \"default\", \"A\", \"B\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjVxF_YQDbeF",
        "outputId": "80a9ef5c-2f69-4f8b-b67a-0ceb8106fe0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:07:47] 총 클래스 수: 74\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:07:48] Best 모델 파일이 없습니다: /content/drive/MyDrive/oraldrug/1.drug_Image_annotation_allOK/modelfiles/fasterbest.pt. 새로운 모델로 시작합니다.\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:08:20] Faster R-CNN 모델 학습 시작 (Epochs: 10, LR: 0.005, Patience: 10)\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:16:30] Epoch [1/10] - Val Loss: 0.1743, Detections: 1228, Avg Conf: 0.1325\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:24:48] Epoch [2/10] - Val Loss: 0.1441, Detections: 1173, Avg Conf: 0.1577\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n",
            "[2025-12-14 15:32:58] Epoch [3/10] - Val Loss: 0.1270, Detections: 1263, Avg Conf: 0.1189\n",
            "════════════════════════════════════════════════════════════════════════════════════════════════════\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2266792930.py:126: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "════════════════════════════════════════<br>\n",
        "▣ 08. YOLO 모델 생성<br>\n",
        "════════════════════════════════════════"
      ],
      "metadata": {
        "id": "OCRDM7l1X34k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Corrected data_dir to point to Google Drive\n",
        "data_dir = '/content/drive/MyDrive/oraldrug/4.drug_Augmentation'\n",
        "\n",
        "#data_dir = r\"D:\\01.project\\EntryPrj\\data\\oraldrug\\1.drug_Image_annotation_allOK\"\n",
        "trans_type = [\"default\"]#, \"A\", \"B\"]\n",
        "for transform_type in trans_type:\n",
        "  Execute_Train(\n",
        "            model_type=\"yolov8\",            # 모델 타입: \"yolov8\" 또는 \"faster\"\n",
        "            data_dir=data_dir,              # 데이터 디렉토리 경로\n",
        "            model_size=\"n\",                 # YOLOv8 모델 크기: \"n\", \"s\", \"m\", \"l\", \"x\"\n",
        "            epochs=1,                      # 학습 에포크 수\n",
        "            batch_size=16,                  # 배치 크기\n",
        "            lr=0.001,                       # 학습률 (YOLOv8 권장: 0.001)\n",
        "            bBestLoad=True,                # Best 모델 로드 여부 (yolobest.pt)\n",
        "            imgsz=640,                      # 이미지 크기\n",
        "            patience=10,                    # Early stopping patience (에포크 수)\n",
        "            train_ratio=0.8,                # 학습/검증 데이터 분할 비율\n",
        "            num_workers=4,         # 데이터 로더 워커 수\n",
        "            transform_type=transform_type   # 데이터 증강 타입: \"default\", \"A\", \"B\"\n",
        "        )"
      ],
      "metadata": {
        "id": "yf61WBQVDkZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Rka7xZLY9nT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}